{
    "datasets": [
        {
            "task": "NER",
            "id": "ronec-romanian-named-entity-corpus-v1-0",
            "dataset_name": "RONEC - Romanian Named Entity Corpus v1.0",
            "dataset_description": "<h3>Description:</h3>\n<p>RONEC, the ROmanian Named Entity Corpus, holds in its 1.0 version a number of 5127 sentences, annotated with 16 classes, having in total 26376 annotated entities.</p>\n<h3>Input, Output and Metrics:</h3>\n<p>Given the train &amp; validation sets, the target is to maximize the F1 score on the test set.</p>\n<p>Please see this <a href=\"http://www.davidsbatista.net/blog/2018/05/09/Named_Entity_Evaluation/\">resource</a> to understand more about NER evaluation.</p>\n<p>Metric reported is the <strong>Exact Match F1 score</strong>.</p>\n<h3>Download from:</h3>\n<p><a href=\"https://github.com/dumitrescustefan/ronec\">https://github.com/dumitrescustefan/ronec</a></p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Dumitrescu, Stefan Daniel, and Andrei-Marius Avram. \"Introducing RONEC--the Romanian Named Entity Corpus.\" arXiv preprint arXiv:1909.01247 (2019).</p>\n</blockquote>\n<p>or in .bibtex format:</p>\n<blockquote>\n<pre><code>@article{dumitrescu2019introducing,   \n  title={Introducing RONEC--the Romanian Named Entity Corpus},   \n  author={Dumitrescu, Stefan Daniel and Avram, Andrei-Marius},   \n  journal={arXiv preprint arXiv:1909.01247},   \n  year={2019}   \n}\n</code></pre>\n</blockquote>",
            "dataset_link": "https://github.com/dumitrescustefan/ronec",
            "preferred_metric": "Exact Match F1",
            "license": "MIT",
            "license_url": "",
            "models": [],
            "metrics": [],
            "time_range": [
                "Feb '21",
                "Mar '21"
            ],
            "data_points": []
        },
        {
            "task": "Tokenization",
            "id": "ud-romanian-rrt-treebank-v2-5-tokenization",
            "dataset_name": "UD Romanian RRT Treebank v2.5 - Tokenization",
            "dataset_description": "<h3>Description:</h3>\n<p><a href=\"https://universaldependencies.org/\">Universal Dependencies</a> (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages. </p>\n<p>The Romanian RRT Treebank is the standard treebank for Romanian. </p>\n<p>This page is common for the following tasks:\n- UD Romanian RRT Treebank 2.5 - <strong>Tokenization</strong>\n- UD Romanian RRT Treebank 2.5 - <strong>Sentence Segmentation</strong>\n- UD Romanian RRT Treebank 2.5 - <strong>Lemmatization</strong>\n- UD Romanian RRT Treebank 2.5 - <strong>POS Tagging</strong>\n- UD Romanian RRT Treebank 2.5 - <strong>Dependency parsing</strong></p>\n<h3>Input, Output and Metrics:</h3>\n<p>There are train, dev and test files, in raw format (text) and in the CoNLL-U.\nFull details on the CoNLL-U format are found <a href=\"https://universaldependencies.org/format.html\">here</a></p>\n<p>To perform evaluation, please use the official script available <a href=\"http://universaldependencies.org/conll18/evaluation.html\">here</a>. It offers both prediction_file/gold_file and in-memory functions, evaluating all target metrics in one go.</p>\n<p>Per task metrics (as given by the evaluation script above):\n- <strong>Tokenization</strong>: <strong>Tokens</strong> F1 score\n- <strong>Sentence Segmentation</strong>: <strong>Sentences</strong> F1 score\n- <strong>Lemmatization</strong>: <strong>Lemma</strong> F1 score\n- <strong>POS Tagging</strong>: <strong>UPOS</strong>, <strong>XPOS</strong> and <strong>AllTags</strong>  F1 scores\n- <strong>Dependency parsing</strong>: <strong>UAS</strong> and <strong>LAS</strong> F1 scores</p>\n<h3>Download from:</h3>\n<p>Download the treebank from <a href=\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz?sequence=1&amp;isAllowed=y\">here</a>. Unzip the file.</p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Joakim Nivre, Marie-Catherine de Marneffe, Filip Ginter, Yoav Goldberg, Jan Haji\u010d, Christopher D. Manning, Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, Daniel Zeman. 2016. Universal Dependencies v1: A Multilingual Treebank Collection. In Proceedings of LREC.</p>\n</blockquote>",
            "dataset_link": "https://universaldependencies.org/",
            "preferred_metric": "Tokens F1",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "extra_training_data": true,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2018-10",
                    "model_size": "",
                    "results": {
                        "Tokens F1": 99.74
                    }
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "extra_training_data": true,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2019-04",
                    "model_size": "",
                    "results": {
                        "Tokens F1": 99.71
                    }
                }
            ],
            "metrics": [
                "Tokens F1"
            ],
            "time_range": [
                "Sep '18",
                "Oct '18",
                "Apr '19",
                "May '19"
            ],
            "data_points": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "submission_date": "Oct '18",
                    "Tokens F1": 99.74
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "submission_date": "Apr '19",
                    "Tokens F1": 99.71
                }
            ]
        },
        {
            "task": "Sentence Segmentation",
            "id": "ud-romanian-rrt-treebank-v2-5-sentence-segmentation",
            "dataset_name": "UD Romanian RRT Treebank v2.5 - Sentence Segmentation",
            "dataset_description": "<h3>Description:</h3>\n<p><a href=\"https://universaldependencies.org/\">Universal Dependencies</a> (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages. </p>\n<p>The Romanian RRT Treebank is the standard treebank for Romanian. </p>\n<p>This page is common for the following tasks:\n- UD Romanian RRT Treebank 2.5 - <strong>Tokenization</strong>\n- UD Romanian RRT Treebank 2.5 - <strong>Sentence Segmentation</strong>\n- UD Romanian RRT Treebank 2.5 - <strong>Lemmatization</strong>\n- UD Romanian RRT Treebank 2.5 - <strong>POS Tagging</strong>\n- UD Romanian RRT Treebank 2.5 - <strong>Dependency parsing</strong></p>\n<h3>Input, Output and Metrics:</h3>\n<p>There are train, dev and test files, in raw format (text) and in the CoNLL-U.\nFull details on the CoNLL-U format are found <a href=\"https://universaldependencies.org/format.html\">here</a></p>\n<p>To perform evaluation, please use the official script available <a href=\"http://universaldependencies.org/conll18/evaluation.html\">here</a>. It offers both prediction_file/gold_file and in-memory functions, evaluating all target metrics in one go.</p>\n<p>Per task metrics (as given by the evaluation script above):\n- <strong>Tokenization</strong>: <strong>Tokens</strong> F1 score\n- <strong>Sentence Segmentation</strong>: <strong>Sentences</strong> F1 score\n- <strong>Lemmatization</strong>: <strong>Lemma</strong> F1 score\n- <strong>POS Tagging</strong>: <strong>UPOS</strong>, <strong>XPOS</strong> and <strong>AllTags</strong>  F1 scores\n- <strong>Dependency parsing</strong>: <strong>UAS</strong> and <strong>LAS</strong> F1 scores</p>\n<h3>Download from:</h3>\n<p>Download the treebank from <a href=\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz?sequence=1&amp;isAllowed=y\">here</a>. Unzip the file.</p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Joakim Nivre, Marie-Catherine de Marneffe, Filip Ginter, Yoav Goldberg, Jan Haji\u010d, Christopher D. Manning, Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, Daniel Zeman. 2016. Universal Dependencies v1: A Multilingual Treebank Collection. In Proceedings of LREC.</p>\n</blockquote>",
            "dataset_link": "https://universaldependencies.org/",
            "preferred_metric": "Sentences F1",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "extra_training_data": true,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2018-10",
                    "model_size": "",
                    "results": {
                        "Sentences F1": 95.56
                    }
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "extra_training_data": true,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2019-04",
                    "model_size": "",
                    "results": {
                        "Sentences F1": 95.42
                    }
                }
            ],
            "metrics": [
                "Sentences F1"
            ],
            "time_range": [
                "Sep '18",
                "Oct '18",
                "Apr '19",
                "May '19"
            ],
            "data_points": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "submission_date": "Oct '18",
                    "Sentences F1": 95.56
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "submission_date": "Apr '19",
                    "Sentences F1": 95.42
                }
            ]
        },
        {
            "task": "Lemmatization",
            "id": "ud-romanian-rrt-treebank-v2-5-lemmatization",
            "dataset_name": "UD Romanian RRT Treebank v2.5 - Lemmatization",
            "dataset_description": "<h3>Description:</h3>\n<p><a href=\"https://universaldependencies.org/\">Universal Dependencies</a> (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages. </p>\n<p>The Romanian RRT Treebank is the standard treebank for Romanian. </p>\n<p>This page is common for the following tasks:\n- UD Romanian RRT Treebank 2.5 - <strong>Tokenization</strong>\n- UD Romanian RRT Treebank 2.5 - <strong>Sentence Segmentation</strong>\n- UD Romanian RRT Treebank 2.5 - <strong>Lemmatization</strong>\n- UD Romanian RRT Treebank 2.5 - <strong>POS Tagging</strong>\n- UD Romanian RRT Treebank 2.5 - <strong>Dependency parsing</strong></p>\n<h3>Input, Output and Metrics:</h3>\n<p>There are train, dev and test files, in raw format (text) and in the CoNLL-U.\nFull details on the CoNLL-U format are found <a href=\"https://universaldependencies.org/format.html\">here</a></p>\n<p>To perform evaluation, please use the official script available <a href=\"http://universaldependencies.org/conll18/evaluation.html\">here</a>. It offers both prediction_file/gold_file and in-memory functions, evaluating all target metrics in one go.</p>\n<p>Per task metrics (as given by the evaluation script above):\n- <strong>Tokenization</strong>: <strong>Tokens</strong> F1 score\n- <strong>Sentence Segmentation</strong>: <strong>Sentences</strong> F1 score\n- <strong>Lemmatization</strong>: <strong>Lemma</strong> F1 score\n- <strong>POS Tagging</strong>: <strong>UPOS</strong>, <strong>XPOS</strong> and <strong>AllTags</strong>  F1 scores\n- <strong>Dependency parsing</strong>: <strong>UAS</strong> and <strong>LAS</strong> F1 scores</p>\n<h3>Download from:</h3>\n<p>Download the treebank from <a href=\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz?sequence=1&amp;isAllowed=y\">here</a>. Unzip the file.</p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Joakim Nivre, Marie-Catherine de Marneffe, Filip Ginter, Yoav Goldberg, Jan Haji\u010d, Christopher D. Manning, Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, Daniel Zeman. 2016. Universal Dependencies v1: A Multilingual Treebank Collection. In Proceedings of LREC.</p>\n</blockquote>",
            "dataset_link": "https://universaldependencies.org/",
            "preferred_metric": "Lemma F1",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "extra_training_data": true,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2018-10",
                    "model_size": "",
                    "results": {
                        "Lemma F1": 96.91
                    }
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "extra_training_data": true,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2019-04",
                    "model_size": "",
                    "results": {
                        "Lemma F1": 96.57
                    }
                }
            ],
            "metrics": [
                "Lemma F1"
            ],
            "time_range": [
                "Sep '18",
                "Oct '18",
                "Apr '19",
                "May '19"
            ],
            "data_points": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "submission_date": "Oct '18",
                    "Lemma F1": 96.91
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "submission_date": "Apr '19",
                    "Lemma F1": 96.57
                }
            ]
        },
        {
            "task": "POS Tagging",
            "id": "ud-romanian-rrt-treebank-v2-5-part-of-speech-tagging",
            "dataset_name": "UD Romanian RRT Treebank v2.5 - Part of Speech Tagging",
            "dataset_description": "<h3>Description:</h3>\n<p><a href=\"https://universaldependencies.org/\">Universal Dependencies</a> (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages. </p>\n<p>The Romanian RRT Treebank is the standard treebank for Romanian. </p>\n<p>This page is common for the following tasks:\n- UD Romanian RRT Treebank 2.5 - <strong>Tokenization</strong>\n- UD Romanian RRT Treebank 2.5 - <strong>Sentence Segmentation</strong>\n- UD Romanian RRT Treebank 2.5 - <strong>Lemmatization</strong>\n- UD Romanian RRT Treebank 2.5 - <strong>POS Tagging</strong>\n- UD Romanian RRT Treebank 2.5 - <strong>Dependency parsing</strong></p>\n<h3>Input, Output and Metrics:</h3>\n<p>There are train, dev and test files, in raw format (text) and in the CoNLL-U.\nFull details on the CoNLL-U format are found <a href=\"https://universaldependencies.org/format.html\">here</a></p>\n<p>To perform evaluation, please use the official script available <a href=\"http://universaldependencies.org/conll18/evaluation.html\">here</a>. It offers both prediction_file/gold_file and in-memory functions, evaluating all target metrics in one go.</p>\n<p>Per task metrics (as given by the evaluation script above):\n- <strong>Tokenization</strong>: <strong>Tokens</strong> F1 score\n- <strong>Sentence Segmentation</strong>: <strong>Sentences</strong> F1 score\n- <strong>Lemmatization</strong>: <strong>Lemma</strong> F1 score\n- <strong>POS Tagging</strong>: <strong>UPOS</strong>, <strong>XPOS</strong> and <strong>AllTags</strong>  F1 scores\n- <strong>Dependency parsing</strong>: <strong>UAS</strong> and <strong>LAS</strong> F1 scores</p>\n<h3>Download from:</h3>\n<p>Download the treebank from <a href=\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz?sequence=1&amp;isAllowed=y\">here</a>. Unzip the file.</p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Joakim Nivre, Marie-Catherine de Marneffe, Filip Ginter, Yoav Goldberg, Jan Haji\u010d, Christopher D. Manning, Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, Daniel Zeman. 2016. Universal Dependencies v1: A Multilingual Treebank Collection. In Proceedings of LREC.</p>\n</blockquote>",
            "dataset_link": "https://universaldependencies.org/",
            "preferred_metric": "UPOS F1",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "extra_training_data": true,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2018-10",
                    "model_size": "",
                    "results": {
                        "UPOS F1": 97.42
                    }
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "extra_training_data": true,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2019-04",
                    "model_size": "",
                    "results": {
                        "UPOS F1": 96.96
                    }
                },
                {
                    "model": "Romanian BERT Baseline (bert-base-romanian-uncased-v1)",
                    "extra_training_data": true,
                    "paper_title": "",
                    "paper_link": "",
                    "source_link": "https://github.com/dumitrescustefan/Romanian-Transformers",
                    "submission_date": "2020-05",
                    "model_size": "",
                    "results": {
                        "UPOS F1": 98.18
                    }
                }
            ],
            "metrics": [
                "UPOS F1"
            ],
            "time_range": [
                "Sep '18",
                "Oct '18",
                "Apr '19",
                "May '20",
                "Jun '20"
            ],
            "data_points": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "submission_date": "Oct '18",
                    "UPOS F1": 97.42
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "submission_date": "Apr '19",
                    "UPOS F1": 96.96
                },
                {
                    "model": "Romanian BERT Baseline (bert-base-romanian-uncased-v1)",
                    "submission_date": "May '20",
                    "UPOS F1": 98.18
                }
            ]
        },
        {
            "task": "Dependency Parsing",
            "id": "ud-romanian-rrt-treebank-v2-5-dependency-parsing",
            "dataset_name": "UD Romanian RRT Treebank v2.5 - Dependency Parsing",
            "dataset_description": "<h3>Description:</h3>\n<p><a href=\"https://universaldependencies.org/\">Universal Dependencies</a> (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages. </p>\n<p>The Romanian RRT Treebank is the standard treebank for Romanian. </p>\n<p>This page is common for the following tasks:\n- UD Romanian RRT Treebank 2.5 - <strong>Tokenization</strong>\n- UD Romanian RRT Treebank 2.5 - <strong>Sentence Segmentation</strong>\n- UD Romanian RRT Treebank 2.5 - <strong>Lemmatization</strong>\n- UD Romanian RRT Treebank 2.5 - <strong>POS Tagging</strong>\n- UD Romanian RRT Treebank 2.5 - <strong>Dependency parsing</strong></p>\n<h3>Input, Output and Metrics:</h3>\n<p>There are train, dev and test files, in raw format (text) and in the CoNLL-U.\nFull details on the CoNLL-U format are found <a href=\"https://universaldependencies.org/format.html\">here</a></p>\n<p>To perform evaluation, please use the official script available <a href=\"http://universaldependencies.org/conll18/evaluation.html\">here</a>. It offers both prediction_file/gold_file and in-memory functions, evaluating all target metrics in one go.</p>\n<p>Per task metrics (as given by the evaluation script above):\n- <strong>Tokenization</strong>: <strong>Tokens</strong> F1 score\n- <strong>Sentence Segmentation</strong>: <strong>Sentences</strong> F1 score\n- <strong>Lemmatization</strong>: <strong>Lemma</strong> F1 score\n- <strong>POS Tagging</strong>: <strong>UPOS</strong>, <strong>XPOS</strong> and <strong>AllTags</strong>  F1 scores\n- <strong>Dependency parsing</strong>: <strong>UAS</strong> and <strong>LAS</strong> F1 scores</p>\n<h3>Download from:</h3>\n<p>Download the treebank from <a href=\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz?sequence=1&amp;isAllowed=y\">here</a>. Unzip the file.</p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Joakim Nivre, Marie-Catherine de Marneffe, Filip Ginter, Yoav Goldberg, Jan Haji\u010d, Christopher D. Manning, Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, Daniel Zeman. 2016. Universal Dependencies v1: A Multilingual Treebank Collection. In Proceedings of LREC.</p>\n</blockquote>",
            "dataset_link": "https://universaldependencies.org/",
            "preferred_metric": "UAS F1",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "extra_training_data": true,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2018-10",
                    "model_size": "",
                    "results": {
                        "UAS F1": 90.38,
                        "LAS F1": 85.23
                    }
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "extra_training_data": true,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2019-04",
                    "model_size": "",
                    "results": {
                        "UAS F1": 90.14,
                        "LAS F1": 85.06
                    }
                }
            ],
            "metrics": [
                "UAS F1",
                "LAS F1"
            ],
            "time_range": [
                "Sep '18",
                "Oct '18",
                "Apr '19",
                "May '19"
            ],
            "data_points": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "submission_date": "Oct '18",
                    "UAS F1": 90.38,
                    "LAS F1": 85.23
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "submission_date": "Apr '19",
                    "UAS F1": 90.14,
                    "LAS F1": 85.06
                }
            ]
        },
        {
            "task": "Sentiment Analysis",
            "id": "laroseda",
            "dataset_name": "LaRoSeDa",
            "dataset_description": "<h3>Description:</h3>\n<p>LaRoSeDa, the Large Romanian Sentiment Data Set, contains 15000 product reviews written in Romanian. There are 7500 positive (star ratings 4 and 5) and 7500 negative (star ratings 1 and 2) reviews. The data set is divided into two subsets: training (12000 samples) and test (3000 samples). </p>\n<h3>Input, Output and Metrics:</h3>\n<p>The task is to classify each review according to its star rating. Given the training set, the target is to maximize the macro-averaged F1 score on the test set. </p>\n<p>The reported metric is the <strong>Macro-averaged F1 score</strong>.</p>\n<h3>Download from:</h3>\n<p><a href=\"https://github.com/ancatache/LaRoSeDa\">https://github.com/ancatache/LaRoSeDa</a></p>\n<h3>Starter code:</h3>\n<p>The following script loads the data samples into memory:</p>\n<p><a href=\"https://github.com/ancatache/LaRoSeDa/blob/main/load_data_set.py\">https://github.com/ancatache/LaRoSeDa/blob/main/load_data_set.py</a></p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Anca Maria Tache, Mihaela Gaman, Radu Tudor Ionescu. \"Clustering Word Embeddings with Self-Organizing Maps. Application on LaRoSeDa - A Large Romanian Sentiment Data Set\". arXiv preprint arXiv:2101.04197, 2021. <a href=\"https://arxiv.org/abs/2101.04197\">Read the fulll paper</a>.</p>\n</blockquote>\n<p>or in .bibtex format:</p>\n<blockquote>\n<pre><code>@article{tache2021clustering,\ntitle={Clustering Word Embeddings with Self-Organizing Maps. Application on LaRoSeDa--A Large Romanian Sentiment Data Set},\nauthor={Tache, Anca Maria and Gaman, Mihaela and Ionescu, Radu Tudor},\njournal={arXiv preprint arXiv:2101.04197},\nyear={2021}\n}\n</code></pre>\n</blockquote>",
            "dataset_link": "tbd.",
            "preferred_metric": "F1",
            "license": "Not specified",
            "license_url": "empty",
            "models": [],
            "metrics": [],
            "time_range": [
                "Feb '21",
                "Mar '21"
            ],
            "data_points": []
        },
        {
            "task": "Text Classification",
            "id": "moroco",
            "dataset_name": "MOROCO",
            "dataset_description": "<h3>Description:</h3>\n<p>MOROCO, the Moldavian and Romanian Dialectal Corpus, contains Moldavian and Romanian samples of text collected from the news domain. The samples belong to one of the following six topics: culture, finance, politics, science, sports, tech. The data set is divided into three subsets: training (21719 samples), validation (5921 samples), test (5924 samples).</p>\n<h3>Input, Output and Metrics:</h3>\n<p>The task is to classify each news article into one of the six classes. Given the training and validation sets, the target is to maximize the macro-averaged F1 score on the test set. </p>\n<p>The reported metric is the <strong>Macro-averaged F1 score</strong>.</p>\n<h3>Download from:</h3>\n<p><a href=\"https://github.com/butnaruandrei/MOROCO\">https://github.com/butnaruandrei/MOROCO</a></p>\n<h3>Starter code:</h3>\n<p>The following script loads the data samples into memory:</p>\n<p><a href=\"https://github.com/butnaruandrei/MOROCO/blob/master/loadDataSet.py\">https://github.com/butnaruandrei/MOROCO/blob/master/loadDataSet.py</a></p>\n<p>With minor changes, the following script can be used for the evaluation: </p>\n<p><a href=\"https://github.com/butnaruandrei/MOROCO/blob/master/MOROCO/Var-Dial-MRC-2019-eval/eval.py\">https://github.com/butnaruandrei/MOROCO/blob/master/MOROCO/Var-Dial-MRC-2019-eval/eval.py</a></p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Andrei M. Butnaru, Radu Tudor Ionescu. \"MOROCO: The Moldavian and Romanian Dialectal Corpus\". In Proceedings of ACL, pp. 688\u2013698, 2019. <a href=\"https://www.aclweb.org/anthology/P19-1068/\">Read the fulll paper</a>.</p>\n</blockquote>\n<p>or in .bibtex format:</p>\n<blockquote>\n<pre><code>@inproceedings{butnaru-ionescu-2019-moroco,\ntitle = \"{MOROCO}: The {M}oldavian and {R}omanian Dialectal Corpus\",\nauthor = \"Butnaru, Andrei and Ionescu, Radu Tudor\",\nbooktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\nmonth = jul,\nyear = \"2019\",\nurl = \"https://www.aclweb.org/anthology/P19-1068\",\ndoi = \"10.18653/v1/P19-1068\",\npages = \"688--698\"\n}\n</code></pre>\n</blockquote>",
            "dataset_link": "tbd.",
            "preferred_metric": "F1",
            "license": "Not specified",
            "license_url": "",
            "models": [],
            "metrics": [],
            "time_range": [
                "Feb '21",
                "Mar '21"
            ],
            "data_points": []
        }
    ]
}