{
    "datasets": [
        {
            "task": "NER",
            "id": "ronec-romanian-named-entity-corpus-v2-0",
            "dataset_name": "RONEC - Romanian Named Entity Corpus v2.0",
            "dataset_description": "<p><strong>RONEC</strong> the <strong>RO</strong>manian <strong>N</strong>amed <strong>E</strong>ntity <strong>C</strong>orpus (RONEC), at version 2.0, holds 12330 sentences with over 0.5M tokens, annotated with 15 classes, to a total of 80.283 distinctly annotated entities. The target is to correctly label each token or span of tokens into its appropriate class.</p>",
            "short_description": "<p><strong>RONEC</strong> the <strong>RO</strong>manian <strong>N</strong>amed <strong>E</strong>ntity <strong>C</strong>orpus (RONEC), at version 2.0, holds 12330 sentences with over 0.5M tokens, annotated with 15 classes, to a total of 80.283 distinctly annotated entities. The target is to correctly label each token or span of tokens into its appropriate class.</p>",
            "dataset_info": "<h3>Input, Output and Metrics:</h3>\n<p>Given the train &amp; validation sets, the target is to maximize the F1 strict score on the test set.</p>\n<p>Please see this <a href=\"http://www.davidsbatista.net/blog/2018/05/09/Named_Entity_Evaluation/\">resource</a> to understand more about NER evaluation.</p>\n<p>Metric reported is the <strong>Strict Match F1 score</strong>.</p>\n<h3>Download from:</h3>\n<p><a href=\"https://github.com/dumitrescustefan/ronec\">https://github.com/dumitrescustefan/ronec</a></p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Dumitrescu, Stefan Daniel, and Andrei-Marius Avram. \"Introducing RONEC--the Romanian Named Entity Corpus.\" arXiv preprint arXiv:1909.01247 (2019).</p>\n</blockquote>\n<p>or in .bibtex format:</p>\n<blockquote>\n<pre><code>@article{dumitrescu2019introducing,\n  title={Introducing RONEC--the Romanian Named Entity Corpus},\n  author={Dumitrescu, Stefan Daniel and Avram, Andrei-Marius},\n  journal={arXiv preprint arXiv:1909.01247},\n  year={2019}\n}\n</code></pre>\n</blockquote>",
            "dataset_link": "https://github.com/dumitrescustefan/ronec",
            "preferred_metric": "Strict Match F1",
            "starter_code": "",
            "license": "MIT",
            "license_url": "https://mit-license.org/",
            "models": [
                {
                    "model": "bert-base-romanian-cased-v1",
                    "extra_training_data": false,
                    "paper_title": "The birth of Romanian BERT",
                    "paper_link": "https://www.aclweb.org/anthology/2020.findings-emnlp.387/",
                    "source_link": "https://github.com/dumitrescustefan/Romanian-Transformers",
                    "submission_date": "2020-11",
                    "model_size": "124",
                    "results": {
                        "Strict Match F1": 88.15
                    }
                }
            ],
            "metrics": [
                "Strict Match F1"
            ],
            "time_range": [
                "Oct '20",
                "Nov '20",
                "Dec '20"
            ],
            "data_points": [
                {
                    "model": "bert-base-romanian-cased-v1",
                    "submission_date": "Nov '20",
                    "Strict Match F1": 88.15
                }
            ],
            "task_id": "ner",
            "area": "Natural Language Processing"
        },
        {
            "task": "Tokenization",
            "id": "ud-romanian-rrt-treebank-v2-5-tokenization",
            "dataset_name": "UD Romanian RRT Treebank v2.5 - Tokenization",
            "dataset_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>\n<p>The treebank contains over 200K tokens, and is composed of annotated sentences belonging to a set of different genres. On this dataset the following tasks can be performed: <strong>tokenization</strong>, <strong>sentence segmentation</strong>, <strong>lemmatization</strong>, <strong>part-of-speech tagging</strong> and <strong>dependency parsing</strong>.</p>",
            "short_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>",
            "dataset_info": "<h3>Description:</h3>\n<p><a href=\"https://universaldependencies.org/\">Universal Dependencies</a> (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages. </p>\n<p>The Romanian RRT Treebank is the standard treebank for Romanian. </p>\n<p>This page is common for the following tasks:</p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Tokenization</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Sentence Segmentation</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Lemmatization</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>POS Tagging</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Dependency parsing</strong></p>\n<h3>Input, Output and Metrics:</h3>\n<p>There are train, dev and test files, in raw format (text) and in the CoNLL-U.\nFull details on the CoNLL-U format are found <a href=\"https://universaldependencies.org/format.html\">here</a></p>\n<p>To perform evaluation, please use the official script available <a href=\"http://universaldependencies.org/conll18/evaluation.html\">here</a>. It offers both prediction_file/gold_file and in-memory functions, evaluating all target metrics in one go.</p>\n<p>Per task metrics (as given by the evaluation script above):</p>\n<p>\u2022 <strong>Tokenization</strong>: <strong>Tokens</strong> F1 score</p>\n<p>\u2022 <strong>Sentence Segmentation</strong>: <strong>Sentences</strong> F1 score</p>\n<p>\u2022 <strong>Lemmatization</strong>: <strong>Lemma</strong> F1 score</p>\n<p>\u2022 <strong>POS Tagging</strong>: <strong>UPOS</strong>, <strong>XPOS</strong> and <strong>AllTags</strong>  F1 scores</p>\n<p>\u2022 <strong>Dependency parsing</strong>: <strong>UAS</strong> and <strong>LAS</strong> F1 scores</p>\n<h3>Download from:</h3>\n<p>Download the treebank from <a href=\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz?sequence=1&amp;isAllowed=y\">here</a>. Unzip the file.</p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Joakim Nivre, Marie-Catherine de Marneffe, Filip Ginter, Yoav Goldberg, Jan Haji\u010d, Christopher D. Manning, Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, Daniel Zeman. 2016. Universal Dependencies v1: A Multilingual Treebank Collection. In Proceedings of LREC.</p>\n</blockquote>\n<p>or, in bibtex format:</p>\n<blockquote>\n<p>@inproceedings{nivre-etal-2016-universal,\n   title = \"{U}niversal {D}ependencies v1: A Multilingual Treebank Collection\",\n   author = \"Nivre, Joakim  and\n     de Marneffe, Marie-Catherine  and\n     Ginter, Filip  and\n     Goldberg, Yoav  and\n     Haji{\\v{c}}, Jan  and\n     Manning, Christopher D.  and\n     McDonald, Ryan  and\n     Petrov, Slav  and\n     Pyysalo, Sampo  and\n     Silveira, Natalia  and\n     Tsarfaty, Reut  and\n     Zeman, Daniel\",\n   booktitle = \"Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)\",\n   month = may,\n   year = \"2016\",\n   address = \"Portoro{\\v{z}}, Slovenia\",\n   publisher = \"European Language Resources Association (ELRA)\",\n   url = \"https://www.aclweb.org/anthology/L16-1262\",\n   pages = \"1659--1666\",\n   abstract = \"Cross-linguistically consistent annotation is necessary for sound comparative evaluation and cross-lingual learning experiments. It is also useful for multilingual system development and comparative linguistic studies. Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. In this paper, we describe v1 of the universal guidelines, the underlying design principles, and the currently available treebanks for 33 languages.\",\n}</p>\n</blockquote>",
            "dataset_link": "https://universaldependencies.org/",
            "preferred_metric": "Tokens F1",
            "starter_code": "",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "extra_training_data": false,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2018-10",
                    "model_size": "",
                    "results": {
                        "Tokens F1": 99.74
                    }
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "extra_training_data": false,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2019-04",
                    "model_size": "",
                    "results": {
                        "Tokens F1": 99.71
                    }
                }
            ],
            "metrics": [
                "Tokens F1"
            ],
            "time_range": [
                "Sep '18",
                "Oct '18",
                "Apr '19",
                "May '19"
            ],
            "data_points": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "submission_date": "Oct '18",
                    "Tokens F1": 99.74
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "submission_date": "Apr '19",
                    "Tokens F1": 99.71
                }
            ],
            "task_id": "tokenization",
            "area": "Additional tasks and Resources"
        },
        {
            "task": "Sentence Segmentation",
            "id": "ud-romanian-rrt-treebank-v2-5-sentence-segmentation",
            "dataset_name": "UD Romanian RRT Treebank v2.5 - Sentence Segmentation",
            "dataset_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>\n<p>The treebank contains over 200K tokens, and is composed of annotated sentences belonging to a set of different genres. On this dataset the following tasks can be performed: <strong>tokenization</strong>, <strong>sentence segmentation</strong>, <strong>lemmatization</strong>, <strong>part-of-speech tagging</strong> and <strong>dependency parsing</strong>.</p>",
            "short_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>",
            "dataset_info": "<h3>Description:</h3>\n<p><a href=\"https://universaldependencies.org/\">Universal Dependencies</a> (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages. </p>\n<p>The Romanian RRT Treebank is the standard treebank for Romanian. </p>\n<p>This page is common for the following tasks:</p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Tokenization</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Sentence Segmentation</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Lemmatization</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>POS Tagging</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Dependency parsing</strong></p>\n<h3>Input, Output and Metrics:</h3>\n<p>There are train, dev and test files, in raw format (text) and in the CoNLL-U.\nFull details on the CoNLL-U format are found <a href=\"https://universaldependencies.org/format.html\">here</a></p>\n<p>To perform evaluation, please use the official script available <a href=\"http://universaldependencies.org/conll18/evaluation.html\">here</a>. It offers both prediction_file/gold_file and in-memory functions, evaluating all target metrics in one go.</p>\n<p>Per task metrics (as given by the evaluation script above):</p>\n<p>\u2022 <strong>Tokenization</strong>: <strong>Tokens</strong> F1 score</p>\n<p>\u2022 <strong>Sentence Segmentation</strong>: <strong>Sentences</strong> F1 score</p>\n<p>\u2022 <strong>Lemmatization</strong>: <strong>Lemma</strong> F1 score</p>\n<p>\u2022 <strong>POS Tagging</strong>: <strong>UPOS</strong>, <strong>XPOS</strong> and <strong>AllTags</strong>  F1 scores</p>\n<p>\u2022 <strong>Dependency parsing</strong>: <strong>UAS</strong> and <strong>LAS</strong> F1 scores</p>\n<h3>Download from:</h3>\n<p>Download the treebank from <a href=\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz?sequence=1&amp;isAllowed=y\">here</a>. Unzip the file.</p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Joakim Nivre, Marie-Catherine de Marneffe, Filip Ginter, Yoav Goldberg, Jan Haji\u010d, Christopher D. Manning, Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, Daniel Zeman. 2016. Universal Dependencies v1: A Multilingual Treebank Collection. In Proceedings of LREC.</p>\n</blockquote>\n<p>or, in bibtex format:</p>\n<blockquote>\n<p>@inproceedings{nivre-etal-2016-universal,\n   title = \"{U}niversal {D}ependencies v1: A Multilingual Treebank Collection\",\n   author = \"Nivre, Joakim  and\n     de Marneffe, Marie-Catherine  and\n     Ginter, Filip  and\n     Goldberg, Yoav  and\n     Haji{\\v{c}}, Jan  and\n     Manning, Christopher D.  and\n     McDonald, Ryan  and\n     Petrov, Slav  and\n     Pyysalo, Sampo  and\n     Silveira, Natalia  and\n     Tsarfaty, Reut  and\n     Zeman, Daniel\",\n   booktitle = \"Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)\",\n   month = may,\n   year = \"2016\",\n   address = \"Portoro{\\v{z}}, Slovenia\",\n   publisher = \"European Language Resources Association (ELRA)\",\n   url = \"https://www.aclweb.org/anthology/L16-1262\",\n   pages = \"1659--1666\",\n   abstract = \"Cross-linguistically consistent annotation is necessary for sound comparative evaluation and cross-lingual learning experiments. It is also useful for multilingual system development and comparative linguistic studies. Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. In this paper, we describe v1 of the universal guidelines, the underlying design principles, and the currently available treebanks for 33 languages.\",\n}</p>\n</blockquote>",
            "dataset_link": "https://universaldependencies.org/",
            "preferred_metric": "Sentences F1",
            "starter_code": "",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "extra_training_data": false,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2018-10",
                    "model_size": "",
                    "results": {
                        "Sentences F1": 95.56
                    }
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "extra_training_data": false,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2019-04",
                    "model_size": "",
                    "results": {
                        "Sentences F1": 95.42
                    }
                }
            ],
            "metrics": [
                "Sentences F1"
            ],
            "time_range": [
                "Sep '18",
                "Oct '18",
                "Apr '19",
                "May '19"
            ],
            "data_points": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "submission_date": "Oct '18",
                    "Sentences F1": 95.56
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "submission_date": "Apr '19",
                    "Sentences F1": 95.42
                }
            ],
            "task_id": "sentence-segmentation",
            "area": "Additional tasks and Resources"
        },
        {
            "task": "Lemmatization",
            "id": "ud-romanian-rrt-treebank-v2-5-lemmatization",
            "dataset_name": "UD Romanian RRT Treebank v2.5 - Lemmatization",
            "dataset_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>\n<p>The treebank contains over 200K tokens, and is composed of annotated sentences belonging to a set of different genres. On this dataset the following tasks can be performed: <strong>tokenization</strong>, <strong>sentence segmentation</strong>, <strong>lemmatization</strong>, <strong>part-of-speech tagging</strong> and <strong>dependency parsing</strong>.</p>",
            "short_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>",
            "dataset_info": "<h3>Description:</h3>\n<p><a href=\"https://universaldependencies.org/\">Universal Dependencies</a> (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages. </p>\n<p>The Romanian RRT Treebank is the standard treebank for Romanian. </p>\n<p>This page is common for the following tasks:</p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Tokenization</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Sentence Segmentation</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Lemmatization</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>POS Tagging</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Dependency parsing</strong></p>\n<h3>Input, Output and Metrics:</h3>\n<p>There are train, dev and test files, in raw format (text) and in the CoNLL-U.\nFull details on the CoNLL-U format are found <a href=\"https://universaldependencies.org/format.html\">here</a></p>\n<p>To perform evaluation, please use the official script available <a href=\"http://universaldependencies.org/conll18/evaluation.html\">here</a>. It offers both prediction_file/gold_file and in-memory functions, evaluating all target metrics in one go.</p>\n<p>Per task metrics (as given by the evaluation script above):</p>\n<p>\u2022 <strong>Tokenization</strong>: <strong>Tokens</strong> F1 score</p>\n<p>\u2022 <strong>Sentence Segmentation</strong>: <strong>Sentences</strong> F1 score</p>\n<p>\u2022 <strong>Lemmatization</strong>: <strong>Lemma</strong> F1 score</p>\n<p>\u2022 <strong>POS Tagging</strong>: <strong>UPOS</strong>, <strong>XPOS</strong> and <strong>AllTags</strong>  F1 scores</p>\n<p>\u2022 <strong>Dependency parsing</strong>: <strong>UAS</strong> and <strong>LAS</strong> F1 scores</p>\n<h3>Download from:</h3>\n<p>Download the treebank from <a href=\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz?sequence=1&amp;isAllowed=y\">here</a>. Unzip the file.</p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Joakim Nivre, Marie-Catherine de Marneffe, Filip Ginter, Yoav Goldberg, Jan Haji\u010d, Christopher D. Manning, Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, Daniel Zeman. 2016. Universal Dependencies v1: A Multilingual Treebank Collection. In Proceedings of LREC.</p>\n</blockquote>\n<p>or, in bibtex format:</p>\n<blockquote>\n<p>@inproceedings{nivre-etal-2016-universal,\n   title = \"{U}niversal {D}ependencies v1: A Multilingual Treebank Collection\",\n   author = \"Nivre, Joakim  and\n     de Marneffe, Marie-Catherine  and\n     Ginter, Filip  and\n     Goldberg, Yoav  and\n     Haji{\\v{c}}, Jan  and\n     Manning, Christopher D.  and\n     McDonald, Ryan  and\n     Petrov, Slav  and\n     Pyysalo, Sampo  and\n     Silveira, Natalia  and\n     Tsarfaty, Reut  and\n     Zeman, Daniel\",\n   booktitle = \"Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)\",\n   month = may,\n   year = \"2016\",\n   address = \"Portoro{\\v{z}}, Slovenia\",\n   publisher = \"European Language Resources Association (ELRA)\",\n   url = \"https://www.aclweb.org/anthology/L16-1262\",\n   pages = \"1659--1666\",\n   abstract = \"Cross-linguistically consistent annotation is necessary for sound comparative evaluation and cross-lingual learning experiments. It is also useful for multilingual system development and comparative linguistic studies. Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. In this paper, we describe v1 of the universal guidelines, the underlying design principles, and the currently available treebanks for 33 languages.\",\n}</p>\n</blockquote>",
            "dataset_link": "https://universaldependencies.org/",
            "preferred_metric": "Lemma F1",
            "starter_code": "",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "extra_training_data": false,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2018-10",
                    "model_size": "",
                    "results": {
                        "Lemma F1": 96.91
                    }
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "extra_training_data": false,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2019-04",
                    "model_size": "",
                    "results": {
                        "Lemma F1": 96.57
                    }
                }
            ],
            "metrics": [
                "Lemma F1"
            ],
            "time_range": [
                "Sep '18",
                "Oct '18",
                "Apr '19",
                "May '19"
            ],
            "data_points": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "submission_date": "Oct '18",
                    "Lemma F1": 96.91
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "submission_date": "Apr '19",
                    "Lemma F1": 96.57
                }
            ],
            "task_id": "lemmatization",
            "area": "Additional tasks and Resources"
        },
        {
            "task": "POS Tagging",
            "id": "ud-romanian-rrt-treebank-v2-5-part-of-speech-tagging",
            "dataset_name": "UD Romanian RRT Treebank v2.5 - Part of Speech Tagging",
            "dataset_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>\n<p>The treebank contains over 200K tokens, and is composed of annotated sentences belonging to a set of different genres. On this dataset the following tasks can be performed: <strong>tokenization</strong>, <strong>sentence segmentation</strong>, <strong>lemmatization</strong>, <strong>part-of-speech tagging</strong> and <strong>dependency parsing</strong>.</p>",
            "short_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>",
            "dataset_info": "<h3>Description:</h3>\n<p><a href=\"https://universaldependencies.org/\">Universal Dependencies</a> (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages. </p>\n<p>The Romanian RRT Treebank is the standard treebank for Romanian. </p>\n<p>This page is common for the following tasks:</p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Tokenization</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Sentence Segmentation</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Lemmatization</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>POS Tagging</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Dependency parsing</strong></p>\n<h3>Input, Output and Metrics:</h3>\n<p>There are train, dev and test files, in raw format (text) and in the CoNLL-U.\nFull details on the CoNLL-U format are found <a href=\"https://universaldependencies.org/format.html\">here</a></p>\n<p>To perform evaluation, please use the official script available <a href=\"http://universaldependencies.org/conll18/evaluation.html\">here</a>. It offers both prediction_file/gold_file and in-memory functions, evaluating all target metrics in one go.</p>\n<p>Per task metrics (as given by the evaluation script above):</p>\n<p>\u2022 <strong>Tokenization</strong>: <strong>Tokens</strong> F1 score</p>\n<p>\u2022 <strong>Sentence Segmentation</strong>: <strong>Sentences</strong> F1 score</p>\n<p>\u2022 <strong>Lemmatization</strong>: <strong>Lemma</strong> F1 score</p>\n<p>\u2022 <strong>POS Tagging</strong>: <strong>UPOS</strong>, <strong>XPOS</strong> and <strong>AllTags</strong>  F1 scores</p>\n<p>\u2022 <strong>Dependency parsing</strong>: <strong>UAS</strong> and <strong>LAS</strong> F1 scores</p>\n<h3>Download from:</h3>\n<p>Download the treebank from <a href=\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz?sequence=1&amp;isAllowed=y\">here</a>. Unzip the file.</p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Joakim Nivre, Marie-Catherine de Marneffe, Filip Ginter, Yoav Goldberg, Jan Haji\u010d, Christopher D. Manning, Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, Daniel Zeman. 2016. Universal Dependencies v1: A Multilingual Treebank Collection. In Proceedings of LREC.</p>\n</blockquote>\n<p>or, in bibtex format:</p>\n<blockquote>\n<p>@inproceedings{nivre-etal-2016-universal,\n   title = \"{U}niversal {D}ependencies v1: A Multilingual Treebank Collection\",\n   author = \"Nivre, Joakim  and\n     de Marneffe, Marie-Catherine  and\n     Ginter, Filip  and\n     Goldberg, Yoav  and\n     Haji{\\v{c}}, Jan  and\n     Manning, Christopher D.  and\n     McDonald, Ryan  and\n     Petrov, Slav  and\n     Pyysalo, Sampo  and\n     Silveira, Natalia  and\n     Tsarfaty, Reut  and\n     Zeman, Daniel\",\n   booktitle = \"Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)\",\n   month = may,\n   year = \"2016\",\n   address = \"Portoro{\\v{z}}, Slovenia\",\n   publisher = \"European Language Resources Association (ELRA)\",\n   url = \"https://www.aclweb.org/anthology/L16-1262\",\n   pages = \"1659--1666\",\n   abstract = \"Cross-linguistically consistent annotation is necessary for sound comparative evaluation and cross-lingual learning experiments. It is also useful for multilingual system development and comparative linguistic studies. Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. In this paper, we describe v1 of the universal guidelines, the underlying design principles, and the currently available treebanks for 33 languages.\",\n}</p>\n</blockquote>",
            "dataset_link": "https://universaldependencies.org/",
            "preferred_metric": "UPOS F1",
            "starter_code": "",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "extra_training_data": false,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2018-10",
                    "model_size": "",
                    "results": {
                        "UPOS F1": 97.42
                    }
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "extra_training_data": false,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2019-04",
                    "model_size": "",
                    "results": {
                        "UPOS F1": 96.96
                    }
                },
                {
                    "model": "Romanian BERT Baseline (bert-base-romanian-uncased-v1)",
                    "extra_training_data": false,
                    "paper_title": "",
                    "paper_link": "",
                    "source_link": "https://github.com/dumitrescustefan/Romanian-Transformers",
                    "submission_date": "2020-05",
                    "model_size": "",
                    "results": {
                        "UPOS F1": 98.18
                    }
                }
            ],
            "metrics": [
                "UPOS F1"
            ],
            "time_range": [
                "Sep '18",
                "Oct '18",
                "Apr '19",
                "May '20",
                "Jun '20"
            ],
            "data_points": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "submission_date": "Oct '18",
                    "UPOS F1": 97.42
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "submission_date": "Apr '19",
                    "UPOS F1": 96.96
                },
                {
                    "model": "Romanian BERT Baseline (bert-base-romanian-uncased-v1)",
                    "submission_date": "May '20",
                    "UPOS F1": 98.18
                }
            ],
            "task_id": "pos-tagging",
            "area": "Additional tasks and Resources"
        },
        {
            "task": "Dependency Parsing",
            "id": "ud-romanian-rrt-treebank-v2-5-dependency-parsing",
            "dataset_name": "UD Romanian RRT Treebank v2.5 - Dependency Parsing",
            "dataset_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>\n<p>The treebank contains over 200K tokens, and is composed of annotated sentences belonging to a set of different genres. On this dataset the following tasks can be performed: <strong>tokenization</strong>, <strong>sentence segmentation</strong>, <strong>lemmatization</strong>, <strong>part-of-speech tagging</strong> and <strong>dependency parsing</strong>.</p>",
            "short_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>",
            "dataset_info": "<h3>Description:</h3>\n<p><a href=\"https://universaldependencies.org/\">Universal Dependencies</a> (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages. </p>\n<p>The Romanian RRT Treebank is the standard treebank for Romanian. </p>\n<p>This page is common for the following tasks:</p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Tokenization</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Sentence Segmentation</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Lemmatization</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>POS Tagging</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Dependency parsing</strong></p>\n<h3>Input, Output and Metrics:</h3>\n<p>There are train, dev and test files, in raw format (text) and in the CoNLL-U.\nFull details on the CoNLL-U format are found <a href=\"https://universaldependencies.org/format.html\">here</a></p>\n<p>To perform evaluation, please use the official script available <a href=\"http://universaldependencies.org/conll18/evaluation.html\">here</a>. It offers both prediction_file/gold_file and in-memory functions, evaluating all target metrics in one go.</p>\n<p>Per task metrics (as given by the evaluation script above):</p>\n<p>\u2022 <strong>Tokenization</strong>: <strong>Tokens</strong> F1 score</p>\n<p>\u2022 <strong>Sentence Segmentation</strong>: <strong>Sentences</strong> F1 score</p>\n<p>\u2022 <strong>Lemmatization</strong>: <strong>Lemma</strong> F1 score</p>\n<p>\u2022 <strong>POS Tagging</strong>: <strong>UPOS</strong>, <strong>XPOS</strong> and <strong>AllTags</strong>  F1 scores</p>\n<p>\u2022 <strong>Dependency parsing</strong>: <strong>UAS</strong> and <strong>LAS</strong> F1 scores</p>\n<h3>Download from:</h3>\n<p>Download the treebank from <a href=\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz?sequence=1&amp;isAllowed=y\">here</a>. Unzip the file.</p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Joakim Nivre, Marie-Catherine de Marneffe, Filip Ginter, Yoav Goldberg, Jan Haji\u010d, Christopher D. Manning, Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, Daniel Zeman. 2016. Universal Dependencies v1: A Multilingual Treebank Collection. In Proceedings of LREC.</p>\n</blockquote>\n<p>or, in bibtex format:</p>\n<blockquote>\n<p>@inproceedings{nivre-etal-2016-universal,\n   title = \"{U}niversal {D}ependencies v1: A Multilingual Treebank Collection\",\n   author = \"Nivre, Joakim  and\n     de Marneffe, Marie-Catherine  and\n     Ginter, Filip  and\n     Goldberg, Yoav  and\n     Haji{\\v{c}}, Jan  and\n     Manning, Christopher D.  and\n     McDonald, Ryan  and\n     Petrov, Slav  and\n     Pyysalo, Sampo  and\n     Silveira, Natalia  and\n     Tsarfaty, Reut  and\n     Zeman, Daniel\",\n   booktitle = \"Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)\",\n   month = may,\n   year = \"2016\",\n   address = \"Portoro{\\v{z}}, Slovenia\",\n   publisher = \"European Language Resources Association (ELRA)\",\n   url = \"https://www.aclweb.org/anthology/L16-1262\",\n   pages = \"1659--1666\",\n   abstract = \"Cross-linguistically consistent annotation is necessary for sound comparative evaluation and cross-lingual learning experiments. It is also useful for multilingual system development and comparative linguistic studies. Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. In this paper, we describe v1 of the universal guidelines, the underlying design principles, and the currently available treebanks for 33 languages.\",\n}</p>\n</blockquote>",
            "dataset_link": "https://universaldependencies.org/",
            "preferred_metric": "UAS F1",
            "starter_code": "",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "extra_training_data": false,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2018-10",
                    "model_size": "",
                    "results": {
                        "UAS F1": 90.38,
                        "LAS F1": 85.23
                    }
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "extra_training_data": false,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2019-04",
                    "model_size": "",
                    "results": {
                        "UAS F1": 90.14,
                        "LAS F1": 85.06
                    }
                }
            ],
            "metrics": [
                "UAS F1",
                "LAS F1"
            ],
            "time_range": [
                "Sep '18",
                "Oct '18",
                "Apr '19",
                "May '19"
            ],
            "data_points": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "submission_date": "Oct '18",
                    "UAS F1": 90.38,
                    "LAS F1": 85.23
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "submission_date": "Apr '19",
                    "UAS F1": 90.14,
                    "LAS F1": 85.06
                }
            ],
            "task_id": "dependency-parsing",
            "area": "Additional tasks and Resources"
        },
        {
            "task": "Sentiment Analysis",
            "id": "laroseda",
            "dataset_name": "LaRoSeDa",
            "dataset_description": "<p><strong>LaRoSeDa</strong>, the Large Romanian Sentiment Data Set, contains 15000 product reviews written in Romanian. There are 7500 positive (star ratings 4 and 5) and 7500 negative (star ratings 1 and 2) reviews. </p>",
            "short_description": "<p><strong>LaRoSeDa</strong>, the Large Romanian Sentiment Data Set, contains 15000 product reviews written in Romanian. There are 7500 positive (star ratings 4 and 5) and 7500 negative (star ratings 1 and 2) reviews. </p>",
            "dataset_info": "<h3>Input, Output and Metrics:</h3>\n<p>The task is to classify each review according to its star rating. Given the training set, the target is to maximize the macro-averaged F1 score on the test set.</p>\n<p>The reported metric is the <strong>Macro-averaged F1 score</strong>.</p>\n<h3>Download from:</h3>\n<p><a href=\"https://github.com/ancatache/LaRoSeDa\">https://github.com/ancatache/LaRoSeDa</a></p>\n<h3>Starter code:</h3>\n<p>The following script loads the data samples into memory:</p>\n<p><a href=\"https://github.com/ancatache/LaRoSeDa/blob/main/load_data_set.py\">https://github.com/ancatache/LaRoSeDa/blob/main/load_data_set.py</a></p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Anca Maria Tache, Mihaela Gaman, Radu Tudor Ionescu. \"Clustering Word Embeddings with Self-Organizing Maps. Application on LaRoSeDa - A Large Romanian Sentiment Data Set\". arXiv preprint arXiv:2101.04197, 2021. <a href=\"https://arxiv.org/abs/2101.04197\">Read the full paper</a>.</p>\n</blockquote>\n<p>or in .bibtex format:</p>\n<blockquote>\n<pre><code>@article{tache2021clustering,\ntitle={Clustering Word Embeddings with Self-Organizing Maps. Application on LaRoSeDa--A Large Romanian Sentiment Data Set},\nauthor={Tache, Anca Maria and Gaman, Mihaela and Ionescu, Radu Tudor},\njournal={arXiv preprint arXiv:2101.04197},\nyear={2021}\n}\n</code></pre>\n</blockquote>",
            "dataset_link": "https://github.com/ancatache/LaRoSeDa",
            "preferred_metric": "F1 (macro)",
            "starter_code": "",
            "license": "CC BY-NC-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-nc-sa/4.0/",
            "models": [
                {
                    "model": "HISK+BOWE-BERT with SOMs",
                    "extra_training_data": false,
                    "paper_title": "Clustering Word Embeddings with Self-Organizing Maps. Application on LaRoSeDa -- A Large Romanian Sentiment Data Set",
                    "paper_link": "https://www.aclweb.org/anthology/2021.eacl-main.81/",
                    "source_link": "https://github.com/ancatache/LaRoSeDa",
                    "submission_date": "2021-01",
                    "model_size": "",
                    "results": {
                        "F1 (macro)": 54.3
                    }
                }
            ],
            "metrics": [
                "F1 (macro)"
            ],
            "time_range": [
                "Dec '20",
                "Jan '21",
                "Feb '21"
            ],
            "data_points": [
                {
                    "model": "HISK+BOWE-BERT with SOMs",
                    "submission_date": "Jan '21",
                    "F1 (macro)": 54.3
                }
            ],
            "task_id": "sentiment-analysis",
            "area": "Natural Language Processing"
        },
        {
            "task": "Text Categorization by Topic",
            "id": "moroco",
            "dataset_name": "MOROCO",
            "dataset_description": "<p><strong>MOROCO</strong>, the Moldavian and Romanian Dialectal Corpus, contains Moldavian and Romanian samples of text collected from the news domain. The samples belong to one of the following six topics: culture, finance, politics, science, sports, tech. The data set is divided into three subsets: training (21719 samples), validation (5921 samples), test (5924 samples). The task is to classify each news article into its correct topic (category).</p>",
            "short_description": "<p><strong>MOROCO</strong>, the Moldavian and Romanian Dialectal Corpus, contains Moldavian and Romanian samples of text collected from the news domain. The samples belong to one of the following six topics: culture, finance, politics, science, sports, tech. The data set is divided into three subsets: training (21719 samples), validation (5921 samples), test (5924 samples). The task is to classify each news article into its correct topic (category).</p>",
            "dataset_info": "<h3>Input, Output and Metrics:</h3>\n<p>The task is to classify each news article into one of the six classes. Given the training and validation sets, the target is to maximize the macro-averaged F1 score on the test set.</p>\n<p>The reported metric is the <strong>Macro-averaged F1 score</strong>.</p>\n<h3>Download from:</h3>\n<p><a href=\"https://github.com/butnaruandrei/MOROCO\">https://github.com/butnaruandrei/MOROCO</a></p>\n<h3>Starter code:</h3>\n<p>The following script loads the data samples into memory:</p>\n<p><a href=\"https://github.com/butnaruandrei/MOROCO/blob/master/loadDataSet.py\">https://github.com/butnaruandrei/MOROCO/blob/master/loadDataSet.py</a></p>\n<p>With minor changes, the following script can be used for the evaluation:</p>\n<p><a href=\"https://github.com/butnaruandrei/MOROCO/blob/master/MOROCO/Var-Dial-MRC-2019-eval/eval.py\">https://github.com/butnaruandrei/MOROCO/blob/master/MOROCO/Var-Dial-MRC-2019-eval/eval.py</a></p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Andrei M. Butnaru, Radu Tudor Ionescu. \"MOROCO: The Moldavian and Romanian Dialectal Corpus\". In Proceedings of ACL, pp. 688\u2013698, 2019. <a href=\"https://www.aclweb.org/anthology/P19-1068/\">Read the full paper</a>.</p>\n</blockquote>\n<p>or in .bibtex format:</p>\n<blockquote>\n<pre><code>@inproceedings{butnaru-ionescu-2019-moroco,\ntitle = \"{MOROCO}: The {M}oldavian and {R}omanian Dialectal Corpus\",\nauthor = \"Butnaru, Andrei and Ionescu, Radu Tudor\",\nbooktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\nmonth = jul,\nyear = \"2019\",\nurl = \"https://www.aclweb.org/anthology/P19-1068\",\ndoi = \"10.18653/v1/P19-1068\",\npages = \"688--698\"\n}\n</code></pre>\n</blockquote>",
            "dataset_link": "https://github.com/butnaruandrei/MOROCO",
            "preferred_metric": "F1 (macro)",
            "starter_code": "",
            "license": "CC BY-NC-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-nc-sa/4.0/",
            "models": [
                {
                    "model": "Ensemble based on Classifier Stacking",
                    "extra_training_data": false,
                    "paper_title": "The Unreasonable Effectiveness of Machine Learning in Moldavian versus Romanian Dialect Identification",
                    "paper_link": "https://arxiv.org/abs/2007.15700",
                    "source_link": "",
                    "submission_date": "2020-07",
                    "model_size": "",
                    "results": {
                        "F1 (macro)": 88.03
                    }
                }
            ],
            "metrics": [
                "F1 (macro)"
            ],
            "time_range": [
                "Jun '20",
                "Jul '20",
                "Aug '20"
            ],
            "data_points": [
                {
                    "model": "Ensemble based on Classifier Stacking",
                    "submission_date": "Jul '20",
                    "F1 (macro)": 88.03
                }
            ],
            "task_id": "text-categorization-by-topic",
            "area": "Natural Language Processing"
        },
        {
            "task": "Semantic Textual Similarity",
            "id": "ro-sts",
            "dataset_name": "RO-STS",
            "dataset_description": "<p>The <strong>Romanian Semantic Textual Similarity Dataset</strong> <a href=\"https://github.com/dumitrescustefan/RO-STS\">RO-STS</a> is a high quality translation of the English <a href=\"https://ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark\">STS</a> dataset that contains Romanian sentence pairs with their similarity scores.</p>\n<p>The dataset consists of 8628 sentence pairs in Romanian belonging to categories such as news headlines, image captions and user forums. On this dataset the task of <strong>semantic similarity scoring</strong> can be performed.</p>",
            "short_description": "<p>The <strong>Romanian Semantic Textual Similarity Dataset</strong> <a href=\"https://github.com/dumitrescustefan/RO-STS\">RO-STS</a> is a high quality translation of the English <a href=\"https://ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark\">STS</a> dataset that contains Romanian sentence pairs with their similarity scores.</p>",
            "dataset_info": "<h3>Input, Output and Metrics:</h3>\n<p>The task is to measure how similar two given sentences are.</p>\n<p>Given the train &amp; validation sets, the target is to maximize the Pearson or Spearman correlations on the test set.</p>\n<p>The reported metric is the <strong>Pearson or Spearman coefficient</strong>.</p>\n<h3>Download from:</h3>\n<p><a href=\"https://github.com/dumitrescustefan/RO-STS/\">https://github.com/dumitrescustefan/RO-STS/</a>\n<a href=\"https://github.com/dumitrescustefan/RO-STS/tree/master/dataset/text-similarity\">Direct download of dataset</a></p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<pre><code>@inproceedings{\n  liro2021,\n  title={LiRo: Benchmark and leaderboard for Romanian language tasks},\n  author={Stefan Daniel Dumitrescu and Petru Rebeja and Beata Lorincz and Mihaela Gaman and Andrei Avram and Mihai Ilie and Andrei Pruteanu and Adriana Stan and Lorena Rosia and Cristina Iacobescu and Luciana Morogan and George Dima and Gabriel Marchidan and Traian Rebedea and Madalina Chitez and Dani Yogatama and Sebastian Ruder and Radu Tudor Ionescu and Razvan Pascanu and Viorica Patraucean},\n  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)},\n  year={2021},\n  url={https://openreview.net/forum?id=JH61CD7afTv}\n}\n</code></pre>\n</blockquote>",
            "dataset_link": "https://github.com/dumitrescustefan/RO-STS",
            "preferred_metric": "Pearson Correlation",
            "starter_code": "",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [
                {
                    "model": "RO-STS Baseline RNN",
                    "extra_training_data": false,
                    "paper_title": "",
                    "paper_link": "",
                    "source_link": "https://github.com/dumitrescustefan/RO-STS",
                    "submission_date": "2020-02",
                    "model_size": "16",
                    "results": {
                        "Pearson Correlation": 0.6744,
                        "Spearman Correlation": 0.6662
                    }
                },
                {
                    "model": "bert-base-romanian-uncased-v1",
                    "extra_training_data": false,
                    "paper_title": "",
                    "paper_link": "",
                    "source_link": "https://github.com/dumitrescustefan/RO-STS",
                    "submission_date": "2020-02",
                    "model_size": "124",
                    "results": {
                        "Pearson Correlation": 0.8159,
                        "Spearman Correlation": 0.8086
                    }
                },
                {
                    "model": "RO-STS Baseline mBERT (uncased)",
                    "extra_training_data": false,
                    "paper_title": "",
                    "paper_link": "",
                    "source_link": "https://github.com/dumitrescustefan/RO-STS",
                    "submission_date": "2020-02",
                    "model_size": "167",
                    "results": {
                        "Pearson Correlation": 0.769,
                        "Spearman Correlation": 0.765
                    }
                }
            ],
            "metrics": [
                "Pearson Correlation",
                "Spearman Correlation"
            ],
            "time_range": [
                "Jan '20",
                "Feb '20",
                "Mar '20"
            ],
            "data_points": [
                {
                    "model": "RO-STS Baseline RNN",
                    "submission_date": "Feb '20",
                    "Pearson Correlation": 0.6744,
                    "Spearman Correlation": 0.6662
                },
                {
                    "model": "bert-base-romanian-uncased-v1",
                    "submission_date": "Feb '20",
                    "Pearson Correlation": 0.8159,
                    "Spearman Correlation": 0.8086
                },
                {
                    "model": "RO-STS Baseline mBERT (uncased)",
                    "submission_date": "Feb '20",
                    "Pearson Correlation": 0.769,
                    "Spearman Correlation": 0.765
                }
            ],
            "task_id": "semantic-textual-similarity",
            "area": "Natural Language Processing"
        },
        {
            "task": "Machine Translation",
            "id": "ro-sts-parallel",
            "dataset_name": "RO-STS-parallel",
            "dataset_description": "<p>The <strong>Romanian Semantic Textual Similarity Parallel Dataset</strong> <a href=\"https://github.com/dumitrescustefan/RO-STS\">RO-STS-Parallel</a> is a high quality translation of the English <a href=\"https://ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark\">STS</a> dataset that serves as a Romanian English parallel dataset.</p>\n<p>The dataset consists of 17256 sentence pairs in Romanian and English belonging to categories such as news headlines, image captions and user forums. On this dataset the task of <strong>machine translation</strong> can be performed.</p>",
            "short_description": "<p>The <strong>Romanian Semantic Textual Similarity Parallel Dataset</strong> <a href=\"https://github.com/dumitrescustefan/RO-STS\">RO-STS-Parallel</a> is a high quality translation of the English <a href=\"https://ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark\">STS</a> dataset that serves as a Romanian English parallel dataset.</p>",
            "dataset_info": "<h3>Description:</h3>\n<p>RO-STS-parallel, a parallel Romanian-English dataset is obtained by translating the English <a href=\"https://ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark\">STS</a> dataset into Romanian. It contains 17256 sentences in Romanian and English. The data set is divided into three subsets: training (11498 sentence pairs), validation (3000 sentence pairs), test (2758 sentence pairs).</p>\n<h3>Input, Output and Metrics:</h3>\n<p>The task is to translate a sentence from a source to a target language.</p>\n<p>Given the train &amp; validation sets, the target is to maximize the BLEU or ROUGE-L score on the test set.</p>\n<p>The reported metric is the <strong>BLEU or ROUGE-L score</strong>.</p>\n<h3>Download from:</h3>\n<p><a href=\"https://github.com/dumitrescustefan/RO-STS/\">https://github.com/dumitrescustefan/RO-STS/</a>\n<a href=\"https://github.com/dumitrescustefan/RO-STS/tree/master/dataset/ro-en\">Direct download of dataset</a></p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<pre><code>@inproceedings{\n  liro2021,\n  title={LiRo: Benchmark and leaderboard for Romanian language tasks},\n  author={Stefan Daniel Dumitrescu and Petru Rebeja and Beata Lorincz and Mihaela Gaman and Andrei Avram and Mihai Ilie and Andrei Pruteanu and Adriana Stan and Lorena Rosia and Cristina Iacobescu and Luciana Morogan and George Dima and Gabriel Marchidan and Traian Rebedea and Madalina Chitez and Dani Yogatama and Sebastian Ruder and Radu Tudor Ionescu and Razvan Pascanu and Viorica Patraucean},\n  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)},\n  year={2021},\n  url={https://openreview.net/forum?id=JH61CD7afTv}\n}\n</code></pre>\n</blockquote>",
            "dataset_link": "https://github.com/dumitrescustefan/RO-STS",
            "preferred_metric": "BLEU",
            "starter_code": "",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [],
            "metrics": [],
            "time_range": [
                "Nov '22",
                "Dec '22"
            ],
            "data_points": [],
            "task_id": "machine-translation",
            "area": "Natural Language Processing"
        },
        {
            "task": "Machine Translation",
            "id": "wmt16-en-ro",
            "dataset_name": "WMT16-EN-RO",
            "dataset_description": "<p>Workshop on Machine Translation (WMT) is a conference that builds on a series of annual workshops and conferences on\nstatistical machine translation, going back to 2006. In 2016, a dataset for Romanian-English translation was proposed, containing approximately 614k of parallel sentences taken from Europarl and SETTIMES2.</p>",
            "short_description": "<p>Workshop on Machine Translation (WMT) is a conference that builds on a series of annual workshops and conferences on\nstatistical machine translation, going back to 2006. In 2016, a dataset for Romanian-English translation was proposed, containing approximately 614k of parallel sentences taken from Europarl and SETTIMES2.</p>",
            "dataset_info": "<h3>Input, Output and Metrics:</h3>\n<p>Given the train &amp; validation sets, the target is to maximize the BLEU score on the test set.</p>\n<p>The reported metric is the <strong>BLEU score</strong>.</p>\n<h3>Download from:</h3>\n<p><a href=\"https://www.statmt.org/wmt16/translation-task.html\">https://www.statmt.org/wmt16/translation-task.html</a></p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Bojar, Ond\u0159ej, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Matthias Huck, Antonio Jimeno Yepes et al. \"Findings of the 2016 conference on machine translation.\" In Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers, pp. 131-198. 2016.</p>\n</blockquote>\n<p>or in .bibtex format:</p>\n<blockquote>\n<pre><code>@inproceedings{bojar2016findings,\n  title={Findings of the 2016 conference on machine translation},\n  author={Bojar, Ond{\\v{r}}ej and Chatterjee, Rajen and Federmann, Christian and Graham, Yvette and Haddow, Barry and Huck, Matthias and Yepes, Antonio Jimeno and Koehn, Philipp and Logacheva, Varvara and Monz, Christof and others},\n  booktitle={Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers},\n  pages={131--198},\n  year={2016}\n}\n</code></pre>\n</blockquote>",
            "dataset_link": "https://www.statmt.org/wmt16/translation-task.html#download",
            "preferred_metric": "BLEU",
            "starter_code": "",
            "license": "Not specified",
            "license_url": "",
            "models": [
                {
                    "model": "mBART",
                    "extra_training_data": false,
                    "paper_title": "Multilingual Denoising Pre-training for Neural Machine Translation",
                    "paper_link": "https://arxiv.org/abs/2001.08210",
                    "source_link": "",
                    "submission_date": "2020-01",
                    "model_size": "",
                    "results": {
                        "BLEU": 38.5
                    }
                }
            ],
            "metrics": [
                "BLEU"
            ],
            "time_range": [
                "Dec '19",
                "Jan '20",
                "Feb '20"
            ],
            "data_points": [
                {
                    "model": "mBART",
                    "submission_date": "Jan '20",
                    "BLEU": 38.5
                }
            ],
            "task_id": "machine-translation",
            "area": "Natural Language Processing"
        },
        {
            "task": "Question Answering",
            "id": "xquad-ro",
            "dataset_name": "XQuAD-ro",
            "dataset_description": "<p><strong>XQuAD</strong> (Cross-lingual Question Answering Dataset) is a benchmark dataset for evaluating cross-lingual question answering performance. The dataset consists of a subset of 240 paragraphs and 1190 question-answer pairs from the development set of SQuAD v1.1 together with their professional translations into Spanish, German, Greek, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, Hindi and <em>Romanian</em>. Consequently, the dataset is entirely parallel across all languages. The target is to evaluate QA performance on the Romanian section of the corpus, by cross-lingual transfer (e.g. zero-shot on the Romanian data after being trained on one or more languages from the corpus excluding Romanian). </p>",
            "short_description": "<p><strong>XQuAD</strong> (Cross-lingual Question Answering Dataset) is a benchmark dataset for evaluating cross-lingual question answering performance. The dataset consists of a subset of 240 paragraphs and 1190 question-answer pairs from the development set of SQuAD v1.1 together with their professional translations into Spanish, German, Greek, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, Hindi and <em>Romanian</em>. Consequently, the dataset is entirely parallel across all languages. The target is to evaluate QA performance on the Romanian section of the corpus, by cross-lingual transfer (e.g. zero-shot on the Romanian data after being trained on one or more languages from the corpus excluding Romanian). </p>",
            "dataset_info": "<h3>Input, Output and Metrics:</h3>\n<p>XQuAD is intended as an evaluation corpus for zero-shot cross-lingual transfer. Evaluation on the test data should ideally only be conducted at the very end of the experimentation in order to avoid overfitting to the data.</p>\n<p>Please see this <a href=\"https://github.com/deepmind/xquad\">resource</a> to understand more about XQuAD evaluation.</p>\n<p>Metrics reported: <strong>Macro-averaged F1 score</strong> and <strong>Exact Match</strong>.</p>\n<h3>Download from:</h3>\n<p><a href=\"https://github.com/deepmind/xquad\">https://github.com/deepmind/xquad</a></p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<pre><code>@inproceedings{\n  liro2021,\n  title={LiRo: Benchmark and leaderboard for Romanian language tasks},\n  author={Stefan Daniel Dumitrescu and Petru Rebeja and Beata Lorincz and Mihaela Gaman and Andrei Avram and Mihai Ilie and Andrei Pruteanu and Adriana Stan and Lorena Rosia and Cristina Iacobescu and Luciana Morogan and George Dima and Gabriel Marchidan and Traian Rebedea and Madalina Chitez and Dani Yogatama and Sebastian Ruder and Radu Tudor Ionescu and Razvan Pascanu and Viorica Patraucean},\n  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)},\n  year={2021},\n  url={https://openreview.net/forum?id=JH61CD7afTv}\n}\n</code></pre>\n</blockquote>",
            "dataset_link": "https://github.com/deepmind/xquad",
            "preferred_metric": "F1 (macro)",
            "starter_code": "",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [
                {
                    "model": "mBERT",
                    "extra_training_data": true,
                    "paper_title": "(results available online only, Romanian evaluated by DeepMind XQuAD dataset creators)",
                    "paper_link": "https://github.com/deepmind/xquad",
                    "source_link": "",
                    "submission_date": "2020-01",
                    "model_size": "178",
                    "results": {
                        "F1 (macro)": 72.7,
                        "EM": 59.9
                    }
                },
                {
                    "model": "XLM-R Large",
                    "extra_training_data": true,
                    "paper_title": "(results available online only, Romanian evaluated by DeepMind XQuAD dataset creators)",
                    "paper_link": "https://github.com/deepmind/xquad",
                    "source_link": "",
                    "submission_date": "2020-01",
                    "model_size": "550",
                    "results": {
                        "F1 (macro)": 83.6,
                        "EM": 69.7
                    }
                }
            ],
            "metrics": [
                "F1 (macro)",
                "EM"
            ],
            "time_range": [
                "Dec '19",
                "Jan '20",
                "Feb '20"
            ],
            "data_points": [
                {
                    "model": "mBERT",
                    "submission_date": "Jan '20",
                    "F1 (macro)": 72.7,
                    "EM": 59.9
                },
                {
                    "model": "XLM-R Large",
                    "submission_date": "Jan '20",
                    "F1 (macro)": 83.6,
                    "EM": 69.7
                }
            ],
            "task_id": "question-answering",
            "area": "Natural Language Processing"
        },
        {
            "task": "Cross-domain POS Tagging",
            "id": "ud-romanian-rrt-treebank-v2-8-cross-domain-pos-tagging",
            "dataset_name": "UD Romanian RRT Treebank v2.8 - cross-domain PoS tagging",
            "dataset_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.8</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>\n<p>The treebank contains over 200K tokens, and is composed of annotated sentences belonging to a set of different genres. On this dataset the following tasks can be performed: <strong>cross-domain part-of-speech tagging</strong> and <strong>cross-domain dependency parsing</strong>.</p>",
            "short_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.8</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>",
            "dataset_info": "<h3>Description:</h3>\n<p><a href=\"https://universaldependencies.org/\">Universal Dependencies</a> (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages.</p>\n<p>The Romanian RRT Treebank is the standard treebank for Romanian.</p>\n<p>This page is common for the following tasks:</p>\n<p>\u2022 UD Romanian RRT Treebank 2.8 - <strong>Cross-domain POS Tagging</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.8 - <strong>Cross-domain Dependency parsing</strong></p>\n<h3>Input, Output and Metrics:</h3>\n<p>There are train, dev and test files, in raw format (text) and in the CoNLL-U. We trained on a number of selected domains, and test on a domain not included in the train and dev set.\nFull details on the CoNLL-U format are found <a href=\"https://universaldependencies.org/format.html\">here</a></p>\n<p>To perform evaluation, please use the official script available <a href=\"http://universaldependencies.org/conll18/evaluation.html\">here</a>. It offers both prediction_file/gold_file and in-memory functions, evaluating all target metrics in one go.</p>\n<p>Per task metrics (as given by the evaluation script above):</p>\n<p>\u2022 <strong>POS Tagging</strong>: <strong>UPOS</strong>, <strong>XPOS</strong> and <strong>AllTags</strong>  F1 scores</p>\n<p>\u2022 <strong>Dependency parsing</strong>: <strong>UAS</strong> and <strong>LAS</strong> F1 scores</p>\n<h3>Download from:</h3>\n<p>Download the treebank from <a href=\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz?sequence=1&amp;isAllowed=y\">here</a>. Unzip the file.</p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Barbu Mititelu, V., Ion, R., Simionescu, R., Irimia, E., &amp; Perez, C. A. (2016, September). The romanian treebank annotated according to universal dependencies. In Proceedings of the tenth international conference on natural language processing (hrtal2016).</p>\n</blockquote>\n<p>or, in bibtex format:</p>\n<blockquote>\n<pre><code>@inproceedings{barbu2016romanian,\n   title = \"The romanian treebank annotated according to universal dependencies\",\n   author = \"Barbu Mititelu, Verginica and Ion, Radu and Simionescu, Radu and Irimia, Elena and Perez, Cenel-Augusto\",\n   booktitle = \"Proceedings of the tenth international conference on natural language processing (hrtal2016)\",\n   year = \"2016\",\n}\n</code></pre>\n</blockquote>",
            "dataset_link": "https://universaldependencies.org/",
            "preferred_metric": "UPOS F1",
            "starter_code": "",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [
                {
                    "model": "LiRo Baseline Stanza",
                    "extra_training_data": false,
                    "paper_title": "LiRo: Benchmark and leaderboard for Romanian language tasks",
                    "paper_link": "https://openreview.net/forum?id=JH61CD7afTv",
                    "source_link": "",
                    "submission_date": "2021-05",
                    "model_size": "",
                    "results": {
                        "UPOS F1": 95.73
                    }
                }
            ],
            "metrics": [
                "UPOS F1"
            ],
            "time_range": [
                "Apr '21",
                "May '21",
                "Jun '21"
            ],
            "data_points": [
                {
                    "model": "LiRo Baseline Stanza",
                    "submission_date": "May '21",
                    "UPOS F1": 95.73
                }
            ],
            "task_id": "cross-domain-pos-tagging",
            "area": "Additional tasks and Resources"
        },
        {
            "task": "Cross-domain Dependency Parsing",
            "id": "ud-romanian-rrt-treebank-v2-8-cross-domain-dependency-parsing",
            "dataset_name": "UD Romanian RRT Treebank v2.8 - cross-domain Dependency Parsing",
            "dataset_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.8</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>\n<p>The treebank contains over 200K tokens, and is composed of annotated sentences belonging to a set of different genres. On this dataset the following tasks can be performed: <strong>cross-domain part-of-speech tagging</strong> and <strong>cross-domain dependency parsing</strong>.</p>",
            "short_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.8</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>",
            "dataset_info": "<h3>Description:</h3>\n<p><a href=\"https://universaldependencies.org/\">Universal Dependencies</a> (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages.</p>\n<p>The Romanian RRT Treebank is the standard treebank for Romanian.</p>\n<p>This page is common for the following tasks:</p>\n<p>\u2022 UD Romanian RRT Treebank 2.8 - <strong>Cross-domain POS Tagging</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.8 - <strong>Cross-domain Dependency parsing</strong></p>\n<h3>Input, Output and Metrics:</h3>\n<p>There are train, dev and test files, in raw format (text) and in the CoNLL-U. We trained on a number of selected domains, and test on a domain not included in the train and dev set.\nFull details on the CoNLL-U format are found <a href=\"https://universaldependencies.org/format.html\">here</a></p>\n<p>To perform evaluation, please use the official script available <a href=\"http://universaldependencies.org/conll18/evaluation.html\">here</a>. It offers both prediction_file/gold_file and in-memory functions, evaluating all target metrics in one go.</p>\n<p>Per task metrics (as given by the evaluation script above):</p>\n<p>\u2022 <strong>POS Tagging</strong>: <strong>UPOS</strong>, <strong>XPOS</strong> and <strong>AllTags</strong>  F1 scores</p>\n<p>\u2022 <strong>Dependency parsing</strong>: <strong>UAS</strong> and <strong>LAS</strong> F1 scores</p>\n<h3>Download from:</h3>\n<p>Download the treebank from <a href=\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz?sequence=1&amp;isAllowed=y\">here</a>. Unzip the file.</p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Barbu Mititelu, V., Ion, R., Simionescu, R., Irimia, E., &amp; Perez, C. A. (2016, September). The romanian treebank annotated according to universal dependencies. In Proceedings of the tenth international conference on natural language processing (hrtal2016).</p>\n</blockquote>\n<p>or, in bibtex format:</p>\n<blockquote>\n<pre><code>@inproceedings{barbu2016romanian,\n   title = \"The romanian treebank annotated according to universal dependencies\",\n   author = \"Barbu Mititelu, Verginica and Ion, Radu and Simionescu, Radu and Irimia, Elena and Perez, Cenel-Augusto\",\n   booktitle = \"Proceedings of the tenth international conference on natural language processing (hrtal2016)\",\n   year = \"2016\",\n}\n</code></pre>\n</blockquote>",
            "dataset_link": "https://universaldependencies.org/",
            "preferred_metric": "UAS F1",
            "starter_code": "",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [
                {
                    "model": "LiRo Baseline Stanza",
                    "extra_training_data": false,
                    "paper_title": "LiRo: Benchmark and leaderboard for Romanian language tasks",
                    "paper_link": "https://openreview.net/forum?id=JH61CD7afTv",
                    "source_link": "",
                    "submission_date": "2021-05",
                    "model_size": "",
                    "results": {
                        "UAS F1": 88.97
                    }
                }
            ],
            "metrics": [
                "UAS F1"
            ],
            "time_range": [
                "Apr '21",
                "May '21",
                "Jun '21"
            ],
            "data_points": [
                {
                    "model": "LiRo Baseline Stanza",
                    "submission_date": "May '21",
                    "UAS F1": 88.97
                }
            ],
            "task_id": "cross-domain-dependency-parsing",
            "area": "Additional tasks and Resources"
        },
        {
            "task": "Language Modeling",
            "id": "wiki-ro",
            "dataset_name": "Wiki-Ro",
            "dataset_description": "<p>The <strong>Wiki-ro</strong> corpus consists of cleaned text extracted from the Romanian Wikipedia. This corpus is meant to test the capacity of a Language Model (LM) by measuring its perplexity on the test set after being trained solely on the training data. LMs pretrained on external data can be tested as well, but will have the flag marking their out-of-domain pretraining.</p>",
            "short_description": "<p>The <strong>Wiki-ro</strong> corpus consists of cleaned text extracted from the Romanian Wikipedia. This corpus is meant to test the capacity of a Language Model (LM) by measuring its perplexity on the test set after being trained solely on the training data. LMs pretrained on external data can be tested as well, but will have the flag marking their out-of-domain pretraining.</p>",
            "dataset_info": "<h3>Input, Output and Metrics:</h3>\n<p>The dataset is divided into train, validation, and test splits, always making sure that a document is entirely included in a single split.</p>\n<p>The train, validation, and test sets have 2.1M lines and 44M words, 14K lines and 276K words, and 16K lines and 327K words, respectively.</p>\n<p>The goal of this dataset is to provide standardized fine-tuning and evaluation of language modelling of Romanian text.</p>\n<h3>Download from:</h3>\n<p><a href=\"https://github.com/dumitrescustefan/wiki-ro\">https://github.com/dumitrescustefan/wiki-ro</a></p>\n<h3>Starter code:</h3>\n<p>Not yet available.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Dumitrescu, S. D., Rebeja, P., Lorincz, B., Gaman, M., Avram, A., Ilie, M., ... &amp; Patraucean, V. (2021). LiRo: Benchmark and leaderboard for Romanian language tasks.</p>\n</blockquote>\n<p>or in .bibtex format:</p>\n<blockquote>\n<pre><code>@article{liro2021,\n  title={LiRo: Benchmark and leaderboard for Romanian language tasks},\n  author={Dumitrescu, Stefan Daniel and Rebeja, Petru and Lorincz, Beata and Gaman, Mihaela and Avram, Andrei and Ilie, Mihai and Pruteanu, Andrei and Stan, Adriana and Rosia, Lorena and Iacobescu, Cristina and others},\n  year={2021}\n}\n</code></pre>\n</blockquote>",
            "dataset_link": "https://github.com/dumitrescustefan/wiki-ro",
            "preferred_metric": "Perplexity",
            "starter_code": "",
            "license": "MIT",
            "license_url": "https://mit-license.org/",
            "models": [
                {
                    "model": "bert-base-romanian-cased-v1",
                    "extra_training_data": false,
                    "paper_title": "LiRo: Benchmark and leaderboard for Romanian language tasks",
                    "paper_link": "https://openreview.net/forum?id=JH61CD7afTv",
                    "source_link": "",
                    "submission_date": "2021-05",
                    "model_size": "124",
                    "results": {
                        "Perplexity": 28.0
                    }
                }
            ],
            "metrics": [
                "Perplexity"
            ],
            "time_range": [
                "Apr '21",
                "May '21",
                "Jun '21"
            ],
            "data_points": [
                {
                    "model": "bert-base-romanian-cased-v1",
                    "submission_date": "May '21",
                    "Perplexity": 28.0
                }
            ],
            "task_id": "language-modeling",
            "area": "Natural Language Processing"
        },
        {
            "task": "Gender debiasing",
            "id": "romanian-word-embeddings",
            "dataset_name": "Romanian word embeddings",
            "dataset_description": "<p>The Romanian word embeddings are fastText Wikipedia supervised word embeddings included in the <a href=\"https://github.com/facebookresearch/MUSE\">MUSE</a> library. \nA list of feminine and masculine Romanian nouns selected based on their frequency in the <a href=\"https://github.com/dumitrescustefan/wiki-ro\">wiki-ro</a> corpus are used for the experiments. The first 3000 most frequent nouns are selected for both genders.</p>\n<p>The embedding file used is included in <a href=\"https://github.com/LiroBenchmark/gender-bias/tree/main/embeddings_ro\">embeddings_ro</a> directory, while the selected feminine and masculine nouns are listed in the <a href=\"https://github.com/LiroBenchmark/gender-bias/tree/main/data_ro\">data_ro</a> directory.</p>",
            "short_description": "<p>The Romanian word embeddings are fastText Wikipedia supervised word embeddings included in the <a href=\"https://github.com/facebookresearch/MUSE\">MUSE</a> library. \nA list of feminine and masculine Romanian nouns selected based on their frequency in the <a href=\"https://github.com/dumitrescustefan/wiki-ro\">wiki-ro</a> corpus are used for the experiments. The first 3000 most frequent nouns are selected for both genders.</p>",
            "dataset_info": "<h3>Input, Output and Metrics:</h3>\n<p>Given the <a href=\"https://github.com/facebookresearch/MUSE\">fastText Romanian embeddings</a>, the target is to maximize the Modified Word Embedding Association Test (<code>MWEAT</code>) score.</p>\n<p>Please see the <a href=\"https://arxiv.org/abs/1909.02224\">paper describing the original debiasing experiment</a> for more info on <code>MWEAT</code>.</p>\n<h3>Download from:</h3>\n<p>The embeddings file used is in the <a href=\"https://github.com/LiroBenchmark/gender-bias/tree/main/embeddings_ro\">embeeding_ro</a> directory; the feminine and masculine nouns are listed in the <a href=\"https://github.com/LiroBenchmark/gender-bias/tree/main/data_ro\">data_ro</a> directory.</p>\n<h3>Starter code:</h3>\n<p>You can use the <a href=\"https://github.com/LiroBenchmark/gender-bias/blob/main/bias_embed_ro.ipynb\">Jupyter Notebook</a> as the starter code.</p>\n<h3>Citation:</h3>\n<p>If you refer to this experiment in a published work, please cite the following:</p>\n<blockquote>\n<pre><code>@inproceedings{\n  liro2021,\n  title={LiRo: Benchmark and leaderboard for Romanian language tasks},\n  author={Stefan Daniel Dumitrescu and Petru Rebeja and Beata Lorincz and Mihaela Gaman and Andrei Avram and Mihai Ilie and Andrei Pruteanu and Adriana Stan and Lorena Rosia and Cristina Iacobescu and Luciana Morogan and George Dima and Gabriel Marchidan and Traian Rebedea and Madalina Chitez and Dani Yogatama and Sebastian Ruder and Radu Tudor Ionescu and Razvan Pascanu and Viorica Patraucean},\n  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)},\n  year={2021},\n  url={https://openreview.net/forum?id=JH61CD7afTv}\n}\n</code></pre>\n</blockquote>",
            "dataset_link": "https://github.com/LiroBenchmark/gender-bias",
            "preferred_metric": "Modified-WEAT",
            "starter_code": "https://github.com/LiroBenchmark/gender-bias/blob/main/bias_embed_ro.ipynb",
            "license": "CC BY-NC 4.0",
            "license_url": "https://creativecommons.org/licenses/by-nc/4.0/",
            "models": [
                {
                    "model": "LiRo Baseline gender debiasing",
                    "extra_training_data": false,
                    "paper_title": "LiRo: Benchmark and leaderboard for Romanian language tasks",
                    "paper_link": "https://openreview.net/forum?id=JH61CD7afTv",
                    "source_link": "https://github.com/LiroBenchmark/gender-bias/blob/main/bias_embed_ro.ipynb",
                    "submission_date": "2021-05",
                    "model_size": "",
                    "results": {
                        "Modified-WEAT": 2.57
                    }
                }
            ],
            "metrics": [
                "Modified-WEAT"
            ],
            "time_range": [
                "Apr '21",
                "May '21",
                "Jun '21"
            ],
            "data_points": [
                {
                    "model": "LiRo Baseline gender debiasing",
                    "submission_date": "May '21",
                    "Modified-WEAT": 2.57
                }
            ],
            "task_id": "gender-debiasing",
            "area": "Natural Language Processing"
        },
        {
            "task": "Sentiment Analysis",
            "id": "romanian-emotions-datasets-v2-redv2",
            "dataset_name": "Romanian Emotions Datasets v2 (REDv2)",
            "dataset_description": "",
            "short_description": "",
            "dataset_info": "",
            "dataset_link": "https://github.com/Alegzandra/RED-Romanian-Emotions-Dataset",
            "preferred_metric": "Hamming Loss",
            "starter_code": "",
            "license": "MIT",
            "license_url": "https://mit-license.org/",
            "models": [
                {
                    "model": "bert-base-romanian-uncased-v1",
                    "extra_training_data": false,
                    "paper_title": "RED v2: Enhancing RED Dataset for Multi-Label Emotion Detection",
                    "paper_link": "http://www.lrec-conf.org/proceedings/lrec2022/pdf/2022.lrec-1.149.pdf",
                    "source_link": "https://github.com/Alegzandra/RED-Romanian-Emotions-Dataset/tree/main/REDv2",
                    "submission_date": "2022-03",
                    "model_size": "124",
                    "results": {
                        "Hamming Loss": 0.1038
                    }
                }
            ],
            "metrics": [
                "Hamming Loss"
            ],
            "time_range": [
                "Feb '22",
                "Mar '22",
                "Apr '22"
            ],
            "data_points": [
                {
                    "model": "bert-base-romanian-uncased-v1",
                    "submission_date": "Mar '22",
                    "Hamming Loss": 0.1038
                }
            ],
            "task_id": "sentiment-analysis",
            "area": "Natural Language Processing"
        }
    ]
}