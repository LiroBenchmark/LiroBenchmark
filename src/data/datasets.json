{
    "datasets": [
        {
            "task": "NER",
            "id": "ronec-romanian-named-entity-corpus-v1-0",
            "dataset_name": "RONEC - Romanian Named Entity Corpus v1.0",
            "dataset_description": "<p><strong>RONEC</strong> the <strong>RO</strong>manian <strong>N</strong>amed <strong>E</strong>ntity <strong>C</strong>orpus, holds in its 1.0 version a number of 5127 sentences, annotated with 16 classes, having in total 26376 annotated entities. The target is to correctly label each token or span of tokens into its appropriate class.  </p>",
            "short_description": "<p><strong>RONEC</strong> the <strong>RO</strong>manian <strong>N</strong>amed <strong>E</strong>ntity <strong>C</strong>orpus, holds in its 1.0 version a number of 5127 sentences, annotated with 16 classes, having in total 26376 annotated entities. The target is to correctly label each token or span of tokens into its appropriate class.  </p>",
            "dataset_info": "<h3>Input, Output and Metrics:</h3>\n<p>Given the train &amp; validation sets, the target is to maximize the F1 score on the test set.</p>\n<p>Please see this <a href=\"http://www.davidsbatista.net/blog/2018/05/09/Named_Entity_Evaluation/\">resource</a> to understand more about NER evaluation.</p>\n<p>Metric reported is the <strong>Exact Match F1 score</strong>.</p>\n<h3>Download from:</h3>\n<p><a href=\"https://github.com/dumitrescustefan/ronec\">https://github.com/dumitrescustefan/ronec</a></p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Dumitrescu, Stefan Daniel, and Andrei-Marius Avram. \"Introducing RONEC--the Romanian Named Entity Corpus.\" arXiv preprint arXiv:1909.01247 (2019).</p>\n</blockquote>\n<p>or in .bibtex format:</p>\n<blockquote>\n<pre><code>@article{dumitrescu2019introducing,\n  title={Introducing RONEC--the Romanian Named Entity Corpus},\n  author={Dumitrescu, Stefan Daniel and Avram, Andrei-Marius},\n  journal={arXiv preprint arXiv:1909.01247},\n  year={2019}\n}\n</code></pre>\n</blockquote>",
            "dataset_link": "https://github.com/dumitrescustefan/ronec",
            "preferred_metric": "Exact Match F1",
            "license": "MIT",
            "license_url": "",
            "models": [],
            "metrics": [],
            "time_range": [
                "May '21",
                "Jun '21"
            ],
            "data_points": [],
            "task_id": "ner",
            "area": "NLP"
        },
        {
            "task": "Tokenization",
            "id": "ud-romanian-rrt-treebank-v2-5-tokenization",
            "dataset_name": "UD Romanian RRT Treebank v2.5 - Tokenization",
            "dataset_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>\n<p>The treebank contains over 200K tokens, and is composed of annotated sentences belonging to a set of different genres. On this dataset the following tasks can be performed: <strong>tokenization</strong>, <strong>sentence segmentation</strong>, <strong>lemmatization</strong>, <strong>part-of-speech tagging</strong> and <strong>dependency parsing</strong>.</p>",
            "short_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>",
            "dataset_info": "<h3>Description:</h3>\n<p><a href=\"https://universaldependencies.org/\">Universal Dependencies</a> (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages. </p>\n<p>The Romanian RRT Treebank is the standard treebank for Romanian. </p>\n<p>This page is common for the following tasks:</p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Tokenization</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Sentence Segmentation</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Lemmatization</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>POS Tagging</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Dependency parsing</strong></p>\n<h3>Input, Output and Metrics:</h3>\n<p>There are train, dev and test files, in raw format (text) and in the CoNLL-U.\nFull details on the CoNLL-U format are found <a href=\"https://universaldependencies.org/format.html\">here</a></p>\n<p>To perform evaluation, please use the official script available <a href=\"http://universaldependencies.org/conll18/evaluation.html\">here</a>. It offers both prediction_file/gold_file and in-memory functions, evaluating all target metrics in one go.</p>\n<p>Per task metrics (as given by the evaluation script above):</p>\n<p>\u2022 <strong>Tokenization</strong>: <strong>Tokens</strong> F1 score</p>\n<p>\u2022 <strong>Sentence Segmentation</strong>: <strong>Sentences</strong> F1 score</p>\n<p>\u2022 <strong>Lemmatization</strong>: <strong>Lemma</strong> F1 score</p>\n<p>\u2022 <strong>POS Tagging</strong>: <strong>UPOS</strong>, <strong>XPOS</strong> and <strong>AllTags</strong>  F1 scores</p>\n<p>\u2022 <strong>Dependency parsing</strong>: <strong>UAS</strong> and <strong>LAS</strong> F1 scores</p>\n<h3>Download from:</h3>\n<p>Download the treebank from <a href=\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz?sequence=1&amp;isAllowed=y\">here</a>. Unzip the file.</p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Joakim Nivre, Marie-Catherine de Marneffe, Filip Ginter, Yoav Goldberg, Jan Haji\u010d, Christopher D. Manning, Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, Daniel Zeman. 2016. Universal Dependencies v1: A Multilingual Treebank Collection. In Proceedings of LREC.</p>\n</blockquote>\n<p>or, in bibtex format:</p>\n<blockquote>\n<p>@inproceedings{nivre-etal-2016-universal,\n   title = \"{U}niversal {D}ependencies v1: A Multilingual Treebank Collection\",\n   author = \"Nivre, Joakim  and\n     de Marneffe, Marie-Catherine  and\n     Ginter, Filip  and\n     Goldberg, Yoav  and\n     Haji{\\v{c}}, Jan  and\n     Manning, Christopher D.  and\n     McDonald, Ryan  and\n     Petrov, Slav  and\n     Pyysalo, Sampo  and\n     Silveira, Natalia  and\n     Tsarfaty, Reut  and\n     Zeman, Daniel\",\n   booktitle = \"Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)\",\n   month = may,\n   year = \"2016\",\n   address = \"Portoro{\\v{z}}, Slovenia\",\n   publisher = \"European Language Resources Association (ELRA)\",\n   url = \"https://www.aclweb.org/anthology/L16-1262\",\n   pages = \"1659--1666\",\n   abstract = \"Cross-linguistically consistent annotation is necessary for sound comparative evaluation and cross-lingual learning experiments. It is also useful for multilingual system development and comparative linguistic studies. Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. In this paper, we describe v1 of the universal guidelines, the underlying design principles, and the currently available treebanks for 33 languages.\",\n}</p>\n</blockquote>",
            "dataset_link": "https://universaldependencies.org/",
            "preferred_metric": "Tokens F1",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "extra_training_data": true,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2018-10",
                    "model_size": "",
                    "results": {
                        "Tokens F1": 99.74
                    }
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "extra_training_data": true,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2019-04",
                    "model_size": "",
                    "results": {
                        "Tokens F1": 99.71
                    }
                }
            ],
            "metrics": [
                "Tokens F1"
            ],
            "time_range": [
                "Sep '18",
                "Oct '18",
                "Apr '19",
                "May '19"
            ],
            "data_points": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "submission_date": "Oct '18",
                    "Tokens F1": 99.74
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "submission_date": "Apr '19",
                    "Tokens F1": 99.71
                }
            ],
            "task_id": "tokenization",
            "area": "NLP"
        },
        {
            "task": "Sentence Segmentation",
            "id": "ud-romanian-rrt-treebank-v2-5-sentence-segmentation",
            "dataset_name": "UD Romanian RRT Treebank v2.5 - Sentence Segmentation",
            "dataset_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>\n<p>The treebank contains over 200K tokens, and is composed of annotated sentences belonging to a set of different genres. On this dataset the following tasks can be performed: <strong>tokenization</strong>, <strong>sentence segmentation</strong>, <strong>lemmatization</strong>, <strong>part-of-speech tagging</strong> and <strong>dependency parsing</strong>.</p>",
            "short_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>",
            "dataset_info": "<h3>Description:</h3>\n<p><a href=\"https://universaldependencies.org/\">Universal Dependencies</a> (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages. </p>\n<p>The Romanian RRT Treebank is the standard treebank for Romanian. </p>\n<p>This page is common for the following tasks:</p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Tokenization</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Sentence Segmentation</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Lemmatization</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>POS Tagging</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Dependency parsing</strong></p>\n<h3>Input, Output and Metrics:</h3>\n<p>There are train, dev and test files, in raw format (text) and in the CoNLL-U.\nFull details on the CoNLL-U format are found <a href=\"https://universaldependencies.org/format.html\">here</a></p>\n<p>To perform evaluation, please use the official script available <a href=\"http://universaldependencies.org/conll18/evaluation.html\">here</a>. It offers both prediction_file/gold_file and in-memory functions, evaluating all target metrics in one go.</p>\n<p>Per task metrics (as given by the evaluation script above):</p>\n<p>\u2022 <strong>Tokenization</strong>: <strong>Tokens</strong> F1 score</p>\n<p>\u2022 <strong>Sentence Segmentation</strong>: <strong>Sentences</strong> F1 score</p>\n<p>\u2022 <strong>Lemmatization</strong>: <strong>Lemma</strong> F1 score</p>\n<p>\u2022 <strong>POS Tagging</strong>: <strong>UPOS</strong>, <strong>XPOS</strong> and <strong>AllTags</strong>  F1 scores</p>\n<p>\u2022 <strong>Dependency parsing</strong>: <strong>UAS</strong> and <strong>LAS</strong> F1 scores</p>\n<h3>Download from:</h3>\n<p>Download the treebank from <a href=\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz?sequence=1&amp;isAllowed=y\">here</a>. Unzip the file.</p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Joakim Nivre, Marie-Catherine de Marneffe, Filip Ginter, Yoav Goldberg, Jan Haji\u010d, Christopher D. Manning, Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, Daniel Zeman. 2016. Universal Dependencies v1: A Multilingual Treebank Collection. In Proceedings of LREC.</p>\n</blockquote>\n<p>or, in bibtex format:</p>\n<blockquote>\n<p>@inproceedings{nivre-etal-2016-universal,\n   title = \"{U}niversal {D}ependencies v1: A Multilingual Treebank Collection\",\n   author = \"Nivre, Joakim  and\n     de Marneffe, Marie-Catherine  and\n     Ginter, Filip  and\n     Goldberg, Yoav  and\n     Haji{\\v{c}}, Jan  and\n     Manning, Christopher D.  and\n     McDonald, Ryan  and\n     Petrov, Slav  and\n     Pyysalo, Sampo  and\n     Silveira, Natalia  and\n     Tsarfaty, Reut  and\n     Zeman, Daniel\",\n   booktitle = \"Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)\",\n   month = may,\n   year = \"2016\",\n   address = \"Portoro{\\v{z}}, Slovenia\",\n   publisher = \"European Language Resources Association (ELRA)\",\n   url = \"https://www.aclweb.org/anthology/L16-1262\",\n   pages = \"1659--1666\",\n   abstract = \"Cross-linguistically consistent annotation is necessary for sound comparative evaluation and cross-lingual learning experiments. It is also useful for multilingual system development and comparative linguistic studies. Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. In this paper, we describe v1 of the universal guidelines, the underlying design principles, and the currently available treebanks for 33 languages.\",\n}</p>\n</blockquote>",
            "dataset_link": "https://universaldependencies.org/",
            "preferred_metric": "Sentences F1",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "extra_training_data": true,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2018-10",
                    "model_size": "",
                    "results": {
                        "Sentences F1": 95.56
                    }
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "extra_training_data": true,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2019-04",
                    "model_size": "",
                    "results": {
                        "Sentences F1": 95.42
                    }
                }
            ],
            "metrics": [
                "Sentences F1"
            ],
            "time_range": [
                "Sep '18",
                "Oct '18",
                "Apr '19",
                "May '19"
            ],
            "data_points": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "submission_date": "Oct '18",
                    "Sentences F1": 95.56
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "submission_date": "Apr '19",
                    "Sentences F1": 95.42
                }
            ],
            "task_id": "sentence-segmentation",
            "area": "NLP"
        },
        {
            "task": "Lemmatization",
            "id": "ud-romanian-rrt-treebank-v2-5-lemmatization",
            "dataset_name": "UD Romanian RRT Treebank v2.5 - Lemmatization",
            "dataset_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>\n<p>The treebank contains over 200K tokens, and is composed of annotated sentences belonging to a set of different genres. On this dataset the following tasks can be performed: <strong>tokenization</strong>, <strong>sentence segmentation</strong>, <strong>lemmatization</strong>, <strong>part-of-speech tagging</strong> and <strong>dependency parsing</strong>.</p>",
            "short_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>",
            "dataset_info": "<h3>Description:</h3>\n<p><a href=\"https://universaldependencies.org/\">Universal Dependencies</a> (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages. </p>\n<p>The Romanian RRT Treebank is the standard treebank for Romanian. </p>\n<p>This page is common for the following tasks:</p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Tokenization</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Sentence Segmentation</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Lemmatization</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>POS Tagging</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Dependency parsing</strong></p>\n<h3>Input, Output and Metrics:</h3>\n<p>There are train, dev and test files, in raw format (text) and in the CoNLL-U.\nFull details on the CoNLL-U format are found <a href=\"https://universaldependencies.org/format.html\">here</a></p>\n<p>To perform evaluation, please use the official script available <a href=\"http://universaldependencies.org/conll18/evaluation.html\">here</a>. It offers both prediction_file/gold_file and in-memory functions, evaluating all target metrics in one go.</p>\n<p>Per task metrics (as given by the evaluation script above):</p>\n<p>\u2022 <strong>Tokenization</strong>: <strong>Tokens</strong> F1 score</p>\n<p>\u2022 <strong>Sentence Segmentation</strong>: <strong>Sentences</strong> F1 score</p>\n<p>\u2022 <strong>Lemmatization</strong>: <strong>Lemma</strong> F1 score</p>\n<p>\u2022 <strong>POS Tagging</strong>: <strong>UPOS</strong>, <strong>XPOS</strong> and <strong>AllTags</strong>  F1 scores</p>\n<p>\u2022 <strong>Dependency parsing</strong>: <strong>UAS</strong> and <strong>LAS</strong> F1 scores</p>\n<h3>Download from:</h3>\n<p>Download the treebank from <a href=\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz?sequence=1&amp;isAllowed=y\">here</a>. Unzip the file.</p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Joakim Nivre, Marie-Catherine de Marneffe, Filip Ginter, Yoav Goldberg, Jan Haji\u010d, Christopher D. Manning, Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, Daniel Zeman. 2016. Universal Dependencies v1: A Multilingual Treebank Collection. In Proceedings of LREC.</p>\n</blockquote>\n<p>or, in bibtex format:</p>\n<blockquote>\n<p>@inproceedings{nivre-etal-2016-universal,\n   title = \"{U}niversal {D}ependencies v1: A Multilingual Treebank Collection\",\n   author = \"Nivre, Joakim  and\n     de Marneffe, Marie-Catherine  and\n     Ginter, Filip  and\n     Goldberg, Yoav  and\n     Haji{\\v{c}}, Jan  and\n     Manning, Christopher D.  and\n     McDonald, Ryan  and\n     Petrov, Slav  and\n     Pyysalo, Sampo  and\n     Silveira, Natalia  and\n     Tsarfaty, Reut  and\n     Zeman, Daniel\",\n   booktitle = \"Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)\",\n   month = may,\n   year = \"2016\",\n   address = \"Portoro{\\v{z}}, Slovenia\",\n   publisher = \"European Language Resources Association (ELRA)\",\n   url = \"https://www.aclweb.org/anthology/L16-1262\",\n   pages = \"1659--1666\",\n   abstract = \"Cross-linguistically consistent annotation is necessary for sound comparative evaluation and cross-lingual learning experiments. It is also useful for multilingual system development and comparative linguistic studies. Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. In this paper, we describe v1 of the universal guidelines, the underlying design principles, and the currently available treebanks for 33 languages.\",\n}</p>\n</blockquote>",
            "dataset_link": "https://universaldependencies.org/",
            "preferred_metric": "Lemma F1",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "extra_training_data": true,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2018-10",
                    "model_size": "",
                    "results": {
                        "Lemma F1": 96.91
                    }
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "extra_training_data": true,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2019-04",
                    "model_size": "",
                    "results": {
                        "Lemma F1": 96.57
                    }
                }
            ],
            "metrics": [
                "Lemma F1"
            ],
            "time_range": [
                "Sep '18",
                "Oct '18",
                "Apr '19",
                "May '19"
            ],
            "data_points": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "submission_date": "Oct '18",
                    "Lemma F1": 96.91
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "submission_date": "Apr '19",
                    "Lemma F1": 96.57
                }
            ],
            "task_id": "lemmatization",
            "area": "NLP"
        },
        {
            "task": "POS Tagging",
            "id": "ud-romanian-rrt-treebank-v2-5-part-of-speech-tagging",
            "dataset_name": "UD Romanian RRT Treebank v2.5 - Part of Speech Tagging",
            "dataset_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>\n<p>The treebank contains over 200K tokens, and is composed of annotated sentences belonging to a set of different genres. On this dataset the following tasks can be performed: <strong>tokenization</strong>, <strong>sentence segmentation</strong>, <strong>lemmatization</strong>, <strong>part-of-speech tagging</strong> and <strong>dependency parsing</strong>.</p>",
            "short_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>",
            "dataset_info": "<h3>Description:</h3>\n<p><a href=\"https://universaldependencies.org/\">Universal Dependencies</a> (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages. </p>\n<p>The Romanian RRT Treebank is the standard treebank for Romanian. </p>\n<p>This page is common for the following tasks:</p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Tokenization</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Sentence Segmentation</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Lemmatization</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>POS Tagging</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Dependency parsing</strong></p>\n<h3>Input, Output and Metrics:</h3>\n<p>There are train, dev and test files, in raw format (text) and in the CoNLL-U.\nFull details on the CoNLL-U format are found <a href=\"https://universaldependencies.org/format.html\">here</a></p>\n<p>To perform evaluation, please use the official script available <a href=\"http://universaldependencies.org/conll18/evaluation.html\">here</a>. It offers both prediction_file/gold_file and in-memory functions, evaluating all target metrics in one go.</p>\n<p>Per task metrics (as given by the evaluation script above):</p>\n<p>\u2022 <strong>Tokenization</strong>: <strong>Tokens</strong> F1 score</p>\n<p>\u2022 <strong>Sentence Segmentation</strong>: <strong>Sentences</strong> F1 score</p>\n<p>\u2022 <strong>Lemmatization</strong>: <strong>Lemma</strong> F1 score</p>\n<p>\u2022 <strong>POS Tagging</strong>: <strong>UPOS</strong>, <strong>XPOS</strong> and <strong>AllTags</strong>  F1 scores</p>\n<p>\u2022 <strong>Dependency parsing</strong>: <strong>UAS</strong> and <strong>LAS</strong> F1 scores</p>\n<h3>Download from:</h3>\n<p>Download the treebank from <a href=\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz?sequence=1&amp;isAllowed=y\">here</a>. Unzip the file.</p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Joakim Nivre, Marie-Catherine de Marneffe, Filip Ginter, Yoav Goldberg, Jan Haji\u010d, Christopher D. Manning, Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, Daniel Zeman. 2016. Universal Dependencies v1: A Multilingual Treebank Collection. In Proceedings of LREC.</p>\n</blockquote>\n<p>or, in bibtex format:</p>\n<blockquote>\n<p>@inproceedings{nivre-etal-2016-universal,\n   title = \"{U}niversal {D}ependencies v1: A Multilingual Treebank Collection\",\n   author = \"Nivre, Joakim  and\n     de Marneffe, Marie-Catherine  and\n     Ginter, Filip  and\n     Goldberg, Yoav  and\n     Haji{\\v{c}}, Jan  and\n     Manning, Christopher D.  and\n     McDonald, Ryan  and\n     Petrov, Slav  and\n     Pyysalo, Sampo  and\n     Silveira, Natalia  and\n     Tsarfaty, Reut  and\n     Zeman, Daniel\",\n   booktitle = \"Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)\",\n   month = may,\n   year = \"2016\",\n   address = \"Portoro{\\v{z}}, Slovenia\",\n   publisher = \"European Language Resources Association (ELRA)\",\n   url = \"https://www.aclweb.org/anthology/L16-1262\",\n   pages = \"1659--1666\",\n   abstract = \"Cross-linguistically consistent annotation is necessary for sound comparative evaluation and cross-lingual learning experiments. It is also useful for multilingual system development and comparative linguistic studies. Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. In this paper, we describe v1 of the universal guidelines, the underlying design principles, and the currently available treebanks for 33 languages.\",\n}</p>\n</blockquote>",
            "dataset_link": "https://universaldependencies.org/",
            "preferred_metric": "UPOS F1",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "extra_training_data": true,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2018-10",
                    "model_size": "",
                    "results": {
                        "UPOS F1": 97.42
                    }
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "extra_training_data": true,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2019-04",
                    "model_size": "",
                    "results": {
                        "UPOS F1": 96.96
                    }
                },
                {
                    "model": "Romanian BERT Baseline (bert-base-romanian-uncased-v1)",
                    "extra_training_data": true,
                    "paper_title": "",
                    "paper_link": "",
                    "source_link": "https://github.com/dumitrescustefan/Romanian-Transformers",
                    "submission_date": "2020-05",
                    "model_size": "",
                    "results": {
                        "UPOS F1": 98.18
                    }
                }
            ],
            "metrics": [
                "UPOS F1"
            ],
            "time_range": [
                "Sep '18",
                "Oct '18",
                "Apr '19",
                "May '20",
                "Jun '20"
            ],
            "data_points": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "submission_date": "Oct '18",
                    "UPOS F1": 97.42
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "submission_date": "Apr '19",
                    "UPOS F1": 96.96
                },
                {
                    "model": "Romanian BERT Baseline (bert-base-romanian-uncased-v1)",
                    "submission_date": "May '20",
                    "UPOS F1": 98.18
                }
            ],
            "task_id": "pos-tagging",
            "area": "NLP"
        },
        {
            "task": "Dependency Parsing",
            "id": "ud-romanian-rrt-treebank-v2-5-dependency-parsing",
            "dataset_name": "UD Romanian RRT Treebank v2.5 - Dependency Parsing",
            "dataset_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>\n<p>The treebank contains over 200K tokens, and is composed of annotated sentences belonging to a set of different genres. On this dataset the following tasks can be performed: <strong>tokenization</strong>, <strong>sentence segmentation</strong>, <strong>lemmatization</strong>, <strong>part-of-speech tagging</strong> and <strong>dependency parsing</strong>.</p>",
            "short_description": "<p><strong>Universal Dependencies</strong> (<a href=\"https://universaldependencies.org/\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\"https://universaldependencies.org/treebanks/ro_rrt/index.html\">standard treebank</a> for the Romanian language.</p>",
            "dataset_info": "<h3>Description:</h3>\n<p><a href=\"https://universaldependencies.org/\">Universal Dependencies</a> (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages. </p>\n<p>The Romanian RRT Treebank is the standard treebank for Romanian. </p>\n<p>This page is common for the following tasks:</p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Tokenization</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Sentence Segmentation</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Lemmatization</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>POS Tagging</strong></p>\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Dependency parsing</strong></p>\n<h3>Input, Output and Metrics:</h3>\n<p>There are train, dev and test files, in raw format (text) and in the CoNLL-U.\nFull details on the CoNLL-U format are found <a href=\"https://universaldependencies.org/format.html\">here</a></p>\n<p>To perform evaluation, please use the official script available <a href=\"http://universaldependencies.org/conll18/evaluation.html\">here</a>. It offers both prediction_file/gold_file and in-memory functions, evaluating all target metrics in one go.</p>\n<p>Per task metrics (as given by the evaluation script above):</p>\n<p>\u2022 <strong>Tokenization</strong>: <strong>Tokens</strong> F1 score</p>\n<p>\u2022 <strong>Sentence Segmentation</strong>: <strong>Sentences</strong> F1 score</p>\n<p>\u2022 <strong>Lemmatization</strong>: <strong>Lemma</strong> F1 score</p>\n<p>\u2022 <strong>POS Tagging</strong>: <strong>UPOS</strong>, <strong>XPOS</strong> and <strong>AllTags</strong>  F1 scores</p>\n<p>\u2022 <strong>Dependency parsing</strong>: <strong>UAS</strong> and <strong>LAS</strong> F1 scores</p>\n<h3>Download from:</h3>\n<p>Download the treebank from <a href=\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz?sequence=1&amp;isAllowed=y\">here</a>. Unzip the file.</p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Joakim Nivre, Marie-Catherine de Marneffe, Filip Ginter, Yoav Goldberg, Jan Haji\u010d, Christopher D. Manning, Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, Daniel Zeman. 2016. Universal Dependencies v1: A Multilingual Treebank Collection. In Proceedings of LREC.</p>\n</blockquote>\n<p>or, in bibtex format:</p>\n<blockquote>\n<p>@inproceedings{nivre-etal-2016-universal,\n   title = \"{U}niversal {D}ependencies v1: A Multilingual Treebank Collection\",\n   author = \"Nivre, Joakim  and\n     de Marneffe, Marie-Catherine  and\n     Ginter, Filip  and\n     Goldberg, Yoav  and\n     Haji{\\v{c}}, Jan  and\n     Manning, Christopher D.  and\n     McDonald, Ryan  and\n     Petrov, Slav  and\n     Pyysalo, Sampo  and\n     Silveira, Natalia  and\n     Tsarfaty, Reut  and\n     Zeman, Daniel\",\n   booktitle = \"Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)\",\n   month = may,\n   year = \"2016\",\n   address = \"Portoro{\\v{z}}, Slovenia\",\n   publisher = \"European Language Resources Association (ELRA)\",\n   url = \"https://www.aclweb.org/anthology/L16-1262\",\n   pages = \"1659--1666\",\n   abstract = \"Cross-linguistically consistent annotation is necessary for sound comparative evaluation and cross-lingual learning experiments. It is also useful for multilingual system development and comparative linguistic studies. Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. In this paper, we describe v1 of the universal guidelines, the underlying design principles, and the currently available treebanks for 33 languages.\",\n}</p>\n</blockquote>",
            "dataset_link": "https://universaldependencies.org/",
            "preferred_metric": "UAS F1",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "extra_training_data": true,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2018-10",
                    "model_size": "",
                    "results": {
                        "UAS F1": 90.38,
                        "LAS F1": 85.23
                    }
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "extra_training_data": true,
                    "paper_title": "NLP-Cube: End-to-End Raw Text Processing With Neural Networks",
                    "paper_link": "http://www.aclweb.org/anthology/K18-2017",
                    "source_link": "https://github.com/adobe/NLP-Cube",
                    "submission_date": "2019-04",
                    "model_size": "",
                    "results": {
                        "UAS F1": 90.14,
                        "LAS F1": 85.06
                    }
                }
            ],
            "metrics": [
                "UAS F1",
                "LAS F1"
            ],
            "time_range": [
                "Sep '18",
                "Oct '18",
                "Apr '19",
                "May '19"
            ],
            "data_points": [
                {
                    "model": "NLP-Cube v1.0 [end-to-end]",
                    "submission_date": "Oct '18",
                    "UAS F1": 90.38,
                    "LAS F1": 85.23
                },
                {
                    "model": "NLP-Cube v1.1 [end-to-end]",
                    "submission_date": "Apr '19",
                    "UAS F1": 90.14,
                    "LAS F1": 85.06
                }
            ],
            "task_id": "dependency-parsing",
            "area": "NLP"
        },
        {
            "task": "Sentiment Analysis",
            "id": "laroseda",
            "dataset_name": "LaRoSeDa",
            "dataset_description": "<p><strong>LaRoSeDa</strong>, the Large Romanian Sentiment Data Set, contains 15000 product reviews written in Romanian. There are 7500 positive (star ratings 4 and 5) and 7500 negative (star ratings 1 and 2) reviews. </p>",
            "short_description": "<p><strong>LaRoSeDa</strong>, the Large Romanian Sentiment Data Set, contains 15000 product reviews written in Romanian. There are 7500 positive (star ratings 4 and 5) and 7500 negative (star ratings 1 and 2) reviews. </p>",
            "dataset_info": "<h3>Input, Output and Metrics:</h3>\n<p>The task is to classify each review according to its star rating. Given the training set, the target is to maximize the macro-averaged F1 score on the test set.</p>\n<p>The reported metric is the <strong>Macro-averaged F1 score</strong>.</p>\n<h3>Download from:</h3>\n<p><a href=\"https://github.com/ancatache/LaRoSeDa\">https://github.com/ancatache/LaRoSeDa</a></p>\n<h3>Starter code:</h3>\n<p>The following script loads the data samples into memory:</p>\n<p><a href=\"https://github.com/ancatache/LaRoSeDa/blob/main/load_data_set.py\">https://github.com/ancatache/LaRoSeDa/blob/main/load_data_set.py</a></p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Anca Maria Tache, Mihaela Gaman, Radu Tudor Ionescu. \"Clustering Word Embeddings with Self-Organizing Maps. Application on LaRoSeDa - A Large Romanian Sentiment Data Set\". arXiv preprint arXiv:2101.04197, 2021. <a href=\"https://arxiv.org/abs/2101.04197\">Read the full paper</a>.</p>\n</blockquote>\n<p>or in .bibtex format:</p>\n<blockquote>\n<pre><code>@article{tache2021clustering,\ntitle={Clustering Word Embeddings with Self-Organizing Maps. Application on LaRoSeDa--A Large Romanian Sentiment Data Set},\nauthor={Tache, Anca Maria and Gaman, Mihaela and Ionescu, Radu Tudor},\njournal={arXiv preprint arXiv:2101.04197},\nyear={2021}\n}\n</code></pre>\n</blockquote>",
            "dataset_link": "https://github.com/ancatache/LaRoSeDa",
            "preferred_metric": "F1 (macro)",
            "license": "CC BY-NC-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-nc-sa/4.0/",
            "models": [
                {
                    "model": "HISK+BOWE-BERT with SOMs",
                    "extra_training_data": true,
                    "paper_title": "Clustering Word Embeddings with Self-Organizing Maps. Application on LaRoSeDa -- A Large Romanian Sentiment Data Set",
                    "paper_link": "https://www.aclweb.org/anthology/2021.eacl-main.81/",
                    "source_link": "https://github.com/ancatache/LaRoSeDa",
                    "submission_date": "2021-01",
                    "model_size": "",
                    "results": {
                        "F1 (macro)": 54.3
                    }
                }
            ],
            "metrics": [
                "F1 (macro)"
            ],
            "time_range": [
                "Dec '20",
                "Jan '21",
                "Feb '21"
            ],
            "data_points": [
                {
                    "model": "HISK+BOWE-BERT with SOMs",
                    "submission_date": "Jan '21",
                    "F1 (macro)": 54.3
                }
            ],
            "task_id": "sentiment-analysis",
            "area": "NLP"
        },
        {
            "task": "Text Classification",
            "id": "moroco",
            "dataset_name": "MOROCO",
            "dataset_description": "<p><strong>MOROCO</strong>, the Moldavian and Romanian Dialectal Corpus, contains Moldavian and Romanian samples of text collected from the news domain. The samples belong to one of the following six topics: culture, finance, politics, science, sports, tech. The data set is divided into three subsets: training (21719 samples), validation (5921 samples), test (5924 samples). The task is to classify each news article into its correct topic (category).</p>",
            "short_description": "<p><strong>MOROCO</strong>, the Moldavian and Romanian Dialectal Corpus, contains Moldavian and Romanian samples of text collected from the news domain. The samples belong to one of the following six topics: culture, finance, politics, science, sports, tech. The data set is divided into three subsets: training (21719 samples), validation (5921 samples), test (5924 samples). The task is to classify each news article into its correct topic (category).</p>",
            "dataset_info": "<h3>Input, Output and Metrics:</h3>\n<p>The task is to classify each news article into one of the six classes. Given the training and validation sets, the target is to maximize the macro-averaged F1 score on the test set.</p>\n<p>The reported metric is the <strong>Macro-averaged F1 score</strong>.</p>\n<h3>Download from:</h3>\n<p><a href=\"https://github.com/butnaruandrei/MOROCO\">https://github.com/butnaruandrei/MOROCO</a></p>\n<h3>Starter code:</h3>\n<p>The following script loads the data samples into memory:</p>\n<p><a href=\"https://github.com/butnaruandrei/MOROCO/blob/master/loadDataSet.py\">https://github.com/butnaruandrei/MOROCO/blob/master/loadDataSet.py</a></p>\n<p>With minor changes, the following script can be used for the evaluation:</p>\n<p><a href=\"https://github.com/butnaruandrei/MOROCO/blob/master/MOROCO/Var-Dial-MRC-2019-eval/eval.py\">https://github.com/butnaruandrei/MOROCO/blob/master/MOROCO/Var-Dial-MRC-2019-eval/eval.py</a></p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Andrei M. Butnaru, Radu Tudor Ionescu. \"MOROCO: The Moldavian and Romanian Dialectal Corpus\". In Proceedings of ACL, pp. 688\u2013698, 2019. <a href=\"https://www.aclweb.org/anthology/P19-1068/\">Read the full paper</a>.</p>\n</blockquote>\n<p>or in .bibtex format:</p>\n<blockquote>\n<pre><code>@inproceedings{butnaru-ionescu-2019-moroco,\ntitle = \"{MOROCO}: The {M}oldavian and {R}omanian Dialectal Corpus\",\nauthor = \"Butnaru, Andrei and Ionescu, Radu Tudor\",\nbooktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\nmonth = jul,\nyear = \"2019\",\nurl = \"https://www.aclweb.org/anthology/P19-1068\",\ndoi = \"10.18653/v1/P19-1068\",\npages = \"688--698\"\n}\n</code></pre>\n</blockquote>",
            "dataset_link": "https://github.com/butnaruandrei/MOROCO",
            "preferred_metric": "F1 (macro)",
            "license": "CC BY-NC-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-nc-sa/4.0/",
            "models": [
                {
                    "model": "Ensemble based on Classifier Stacking",
                    "extra_training_data": true,
                    "paper_title": "The Unreasonable Effectiveness of Machine Learning in Moldavian versus Romanian Dialect Identification",
                    "paper_link": "https://arxiv.org/abs/2007.15700",
                    "source_link": "",
                    "submission_date": "2020-07",
                    "model_size": "",
                    "results": {
                        "F1 (macro)": 88.03
                    }
                }
            ],
            "metrics": [
                "F1 (macro)"
            ],
            "time_range": [
                "Jun '20",
                "Jul '20",
                "Aug '20"
            ],
            "data_points": [
                {
                    "model": "Ensemble based on Classifier Stacking",
                    "submission_date": "Jul '20",
                    "F1 (macro)": 88.03
                }
            ],
            "task_id": "text-classification",
            "area": "NLP"
        },
        {
            "task": "Semantic Textual Similarity",
            "id": "ro-sts",
            "dataset_name": "RO-STS",
            "dataset_description": "<p>The <strong>Romanian Semantic Textual Similarity Dataset</strong> (RO-STS)[https://github.com/dumitrescustefan/RO-STS] is a high quality translation of the English <a href=\"https://ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark\">STS</a> dataset that contains Romanian sentence pairs with their similarity scores.</p>\n<p>The dataset consists of 8628 sentence pairs in Romanian belonging to categories such as news headlines, image captions and user forums. On this dataset the task of <strong>semantic similarity scoring</strong> can be performed.</p>",
            "short_description": "<p>The <strong>Romanian Semantic Textual Similarity Dataset</strong> (RO-STS)[https://github.com/dumitrescustefan/RO-STS] is a high quality translation of the English <a href=\"https://ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark\">STS</a> dataset that contains Romanian sentence pairs with their similarity scores.</p>",
            "dataset_info": "<h3>Input, Output and Metrics:</h3>\n<p>The task is to measure how similar two given sentences are.</p>\n<p>Given the train &amp; validation sets, the target is to maximize the Pearson or Spearman correlations on the test set.</p>\n<p>The reported metric is the <strong>Pearson or Spearman coefficient</strong>.</p>\n<h3>Download from:</h3>\n<p><a href=\"https://github.com/dumitrescustefan/RO-STS/\">https://github.com/dumitrescustefan/RO-STS/</a>\n<a href=\"https://github.com/dumitrescustefan/RO-STS/tree/master/dataset/text-similarity\">Direct download of dataset</a></p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Paper currently under review</p>\n</blockquote>\n<p>or in .bibtex format:</p>\n<blockquote>\n<pre><code>@article{\n}\n</code></pre>\n</blockquote>",
            "dataset_link": "https://github.com/dumitrescustefan/RO-STS",
            "preferred_metric": "Pearson Correlation",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [
                {
                    "model": "RO-STS Baseline RNN",
                    "extra_training_data": true,
                    "paper_title": "",
                    "paper_link": "",
                    "source_link": "https://github.com/dumitrescustefan/RO-STS",
                    "submission_date": "2020-02",
                    "model_size": "16",
                    "results": {
                        "Pearson Correlation": 0.6744,
                        "Spearman Correlation": 0.6662
                    }
                },
                {
                    "model": "RO-STS Baseline Romanian BERT v1 (uncased)",
                    "extra_training_data": true,
                    "paper_title": "",
                    "paper_link": "",
                    "source_link": "https://github.com/dumitrescustefan/RO-STS",
                    "submission_date": "2020-02",
                    "model_size": "124",
                    "results": {
                        "Pearson Correlation": 0.8159,
                        "Spearman Correlation": 0.8086
                    }
                },
                {
                    "model": "RO-STS Baseline mBERT (uncased)",
                    "extra_training_data": true,
                    "paper_title": "",
                    "paper_link": "",
                    "source_link": "https://github.com/dumitrescustefan/RO-STS",
                    "submission_date": "2020-02",
                    "model_size": "167",
                    "results": {
                        "Pearson Correlation": 0.769,
                        "Spearman Correlation": 0.765
                    }
                }
            ],
            "metrics": [
                "Pearson Correlation",
                "Spearman Correlation"
            ],
            "time_range": [
                "Jan '20",
                "Feb '20",
                "Mar '20"
            ],
            "data_points": [
                {
                    "model": "RO-STS Baseline RNN",
                    "submission_date": "Feb '20",
                    "Pearson Correlation": 0.6744,
                    "Spearman Correlation": 0.6662
                },
                {
                    "model": "RO-STS Baseline Romanian BERT v1 (uncased)",
                    "submission_date": "Feb '20",
                    "Pearson Correlation": 0.8159,
                    "Spearman Correlation": 0.8086
                },
                {
                    "model": "RO-STS Baseline mBERT (uncased)",
                    "submission_date": "Feb '20",
                    "Pearson Correlation": 0.769,
                    "Spearman Correlation": 0.765
                }
            ],
            "task_id": "semantic-textual-similarity",
            "area": "NLP"
        },
        {
            "task": "Machine Translation",
            "id": "ro-sts-parallel",
            "dataset_name": "RO-STS-parallel",
            "dataset_description": "<p>The <strong>Romanian Semantic Textual Similarity Parallel Dataset</strong> <a href=\"https://github.com/dumitrescustefan/RO-STS\">RO-STS-Parallel</a> is a high quality translation of the English <a href=\"https://ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark\">STS</a> dataset that serves as a Romanian English parallel dataset.</p>\n<p>The dataset consists of 17256 sentence pairs in Romanian and English belonging to categories such as news headlines, image captions and user forums. On this dataset the task of <strong>machine translation</strong> can be performed.</p>",
            "short_description": "<p>The <strong>Romanian Semantic Textual Similarity Parallel Dataset</strong> <a href=\"https://github.com/dumitrescustefan/RO-STS\">RO-STS-Parallel</a> is a high quality translation of the English <a href=\"https://ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark\">STS</a> dataset that serves as a Romanian English parallel dataset.</p>",
            "dataset_info": "<h3>Description:</h3>\n<p>RO-STS-parallel, a parallel Romanian-English dataset is obtained by translating the English <a href=\"https://ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark\">STS</a> dataset into Romanian. It contains 17256 sentences in Romanian and English. The data set is divided into three subsets: training (11498 sentence pairs), validation (3000 sentence pairs), test (2758 sentence pairs).</p>\n<h3>Input, Output and Metrics:</h3>\n<p>The task is to translate a sentence from a source to a target language.</p>\n<p>Given the train &amp; validation sets, the target is to maximize the BLEU or ROUGE-L score on the test set.</p>\n<p>The reported metric is the <strong>BLEU or ROUGE-L score</strong>.</p>\n<h3>Download from:</h3>\n<p><a href=\"https://github.com/dumitrescustefan/RO-STS/\">https://github.com/dumitrescustefan/RO-STS/</a>\n<a href=\"https://github.com/dumitrescustefan/RO-STS/tree/master/dataset/ro-en\">Direct download of dataset</a></p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Paper currently under review</p>\n</blockquote>\n<p>or in .bibtex format:</p>\n<blockquote>\n<pre><code>@article{\n}\n</code></pre>\n</blockquote>",
            "dataset_link": "https://github.com/dumitrescustefan/RO-STS",
            "preferred_metric": "BLEU",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [],
            "metrics": [],
            "time_range": [
                "May '21",
                "Jun '21"
            ],
            "data_points": [],
            "task_id": "machine-translation",
            "area": "NLP"
        },
        {
            "task": "Machine Translation",
            "id": "wmt16-en-ro",
            "dataset_name": "WMT16-EN-RO",
            "dataset_description": "<p>Workshop on Machine Translation (WMT) is a conference that builds on a series of annual workshops and conferences on\nstatistical machine translation, going back to 2006. In 2016, a dataset for Romanian-English translation was proposed, containing approximately 614k of parallel sentences taken from Europarl and SETTIMES2.</p>",
            "short_description": "<p>Workshop on Machine Translation (WMT) is a conference that builds on a series of annual workshops and conferences on\nstatistical machine translation, going back to 2006. In 2016, a dataset for Romanian-English translation was proposed, containing approximately 614k of parallel sentences taken from Europarl and SETTIMES2.</p>",
            "dataset_info": "<h3>Input, Output and Metrics:</h3>\n<p>Given the train &amp; validation sets, the target is to maximize the BLEU score on the test set.</p>\n<p>The reported metric is the <strong>BLEU score</strong>.</p>\n<h3>Download from:</h3>\n<p><a href=\"https://www.statmt.org/wmt16/translation-task.html\">https://www.statmt.org/wmt16/translation-task.html</a></p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>If you use this dataset in a published work, please cite the following:</p>\n<blockquote>\n<p>Bojar, Ond\u0159ej, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Matthias Huck, Antonio Jimeno Yepes et al. \"Findings of the 2016 conference on machine translation.\" In Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers, pp. 131-198. 2016.</p>\n</blockquote>\n<p>or in .bibtex format:</p>\n<blockquote>\n<pre><code>@inproceedings{bojar2016findings,\n  title={Findings of the 2016 conference on machine translation},\n  author={Bojar, Ond{\\v{r}}ej and Chatterjee, Rajen and Federmann, Christian and Graham, Yvette and Haddow, Barry and Huck, Matthias and Yepes, Antonio Jimeno and Koehn, Philipp and Logacheva, Varvara and Monz, Christof and others},\n  booktitle={Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers},\n  pages={131--198},\n  year={2016}\n}\n</code></pre>\n</blockquote>",
            "dataset_link": "https://www.statmt.org/wmt16/translation-task.html#download",
            "preferred_metric": "BLEU",
            "license": "Not specified",
            "license_url": "",
            "models": [],
            "metrics": [],
            "time_range": [
                "May '21",
                "Jun '21"
            ],
            "data_points": [],
            "task_id": "machine-translation",
            "area": "NLP"
        },
        {
            "task": "Question Answering",
            "id": "xquad-ro",
            "dataset_name": "XQuAD-ro",
            "dataset_description": "<p><strong>XQuAD</strong> (Cross-lingual Question Answering Dataset) is a benchmark dataset for evaluating cross-lingual question answering performance. The dataset consists of a subset of 240 paragraphs and 1190 question-answer pairs from the development set of SQuAD v1.1 together with their professional translations into Spanish, German, Greek, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, Hindi and <em>Romanian</em>. Consequently, the dataset is entirely parallel across all languages. The target is to evaluate QA performance on the Romanian section of the corpus, by cross-lingual transfer (e.g. zero-shot on the Romanian data after being trained on one or more languages from the corpus excluding Romanian). </p>",
            "short_description": "<p><strong>XQuAD</strong> (Cross-lingual Question Answering Dataset) is a benchmark dataset for evaluating cross-lingual question answering performance. The dataset consists of a subset of 240 paragraphs and 1190 question-answer pairs from the development set of SQuAD v1.1 together with their professional translations into Spanish, German, Greek, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, Hindi and <em>Romanian</em>. Consequently, the dataset is entirely parallel across all languages. The target is to evaluate QA performance on the Romanian section of the corpus, by cross-lingual transfer (e.g. zero-shot on the Romanian data after being trained on one or more languages from the corpus excluding Romanian). </p>",
            "dataset_info": "<h3>Input, Output and Metrics:</h3>\n<p>XQuAD is intended as an evaluation corpus for zero-shot cross-lingual transfer. Evaluation on the test data should ideally only be conducted at the very end of the experimentation in order to avoid overfitting to the data.</p>\n<p>Please see this <a href=\"https://github.com/deepmind/xquad\">resource</a> to understand more about XQuAD evaluation.</p>\n<p>Metrics reported: <strong>Macro-averaged F1 score</strong> and <strong>Exact Match</strong>.</p>\n<h3>Download from:</h3>\n<p><a href=\"https://github.com/deepmind/xquad\">https://github.com/deepmind/xquad</a></p>\n<h3>Starter code:</h3>\n<p>Not yet available, please download directly from source.</p>\n<h3>Citation:</h3>\n<p>Coming soon.</p>",
            "dataset_link": "https://github.com/deepmind/xquad",
            "preferred_metric": "F1 (macro)",
            "license": "CC BY-SA 4.0",
            "license_url": "https://creativecommons.org/licenses/by-sa/4.0/",
            "models": [
                {
                    "model": "mBERT",
                    "extra_training_data": true,
                    "paper_title": "(results available online only, Romanian evaluated by DeepMind XQuAD dataset creators)",
                    "paper_link": "https://github.com/deepmind/xquad",
                    "source_link": "",
                    "submission_date": "2020-01",
                    "model_size": "178",
                    "results": {
                        "F1 (macro)": 72.7,
                        "EM": 59.9
                    }
                },
                {
                    "model": "XLM-R Large",
                    "extra_training_data": true,
                    "paper_title": "(results available online only, Romanian evaluated by DeepMind XQuAD dataset creators)",
                    "paper_link": "https://github.com/deepmind/xquad",
                    "source_link": "",
                    "submission_date": "2020-01",
                    "model_size": "550",
                    "results": {
                        "F1 (macro)": 83.6,
                        "EM": 69.7
                    }
                }
            ],
            "metrics": [
                "F1 (macro)",
                "EM"
            ],
            "time_range": [
                "Dec '19",
                "Jan '20",
                "Feb '20"
            ],
            "data_points": [
                {
                    "model": "mBERT",
                    "submission_date": "Jan '20",
                    "F1 (macro)": 72.7,
                    "EM": 59.9
                },
                {
                    "model": "XLM-R Large",
                    "submission_date": "Jan '20",
                    "F1 (macro)": 83.6,
                    "EM": 69.7
                }
            ],
            "task_id": "question-answering",
            "area": "NLP"
        }
    ]
}